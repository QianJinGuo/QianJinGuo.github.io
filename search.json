[{"title":"字节数组妙用","url":"/2022/01/14/字节数组妙用/","content":"\n# 字节属于最小单位\n 例如在Java中，int占用4个字节，long占用8个字节等。基本上所有基本类型(包括String)都可以转换成字节，那么这到底有何作用。\n在实际开发中，经常会用到本地缓存，或使用`Redis`或者`Memcached`来作分布式缓存,Java一般存入缓存中的对象无非是以下几种:\n-   序列化的Java对象：一个Java对象序列化后所占用的字节是按对象中属性个数，方法个数，以及属性的值决定，最小也需要几百个字节来存储，大的话可能需要几万个字节\n-   String(可能是json串)：占用字节由字符串的长度决定\n-   规则的byte[]数组：占用字节由数组长度决定，相比较于String来说，基本类型转换成固定字节的数组，而不是转换成内容长度的String，故字节数组所占用的字节比String更少\n>1.  在大量的缓存数据(亿级以上)的情况下，为了提高空间利用率，切勿将**Java对象**当做缓存的内容\n>2.  字节数组所需空间最少\n\n## 引用\n[字节数组的妙用](https://www.jianshu.com/p/665f4dd77f30)","tags":["jdk"],"categories":["java"]},{"title":"线程执行顺序","url":"/2022/01/14/线程执行顺序/","content":"\n## 线程执行顺序\n> jvm为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证[^1]\n`1.《深入理解Java虚拟机：JVM高级特性与最佳实践》 — 周志明`\n\n如果程序没有正确同步，那么可能会存在数据竞争。JMM对数据竞争的定义如下：\n> 在一个线程中写一个变量，在另一个线程中读取同一个变量，而且写和读没有通过同步来排序\n\n顺序一致性模型有以下**两大特性**：\n1. 一个线程中的所有操作必须按照==程序的顺序==来执行\n2. （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致内存模型中，每一个操作都必须是原子执行且立即对所有线程可见。\n\n```md\n可以把顺序顺序一致模型理解为一个单摆，每一个时刻单摆只能到一个位置，对应过来，任何时刻最多只能有一个线程才能连接到内存。\n由于重排序的影响，实际指令的执行顺序是不可知的，但是不管如何排序，每个操作能够立即对其他线程可见，所以所有线程看到的都是一样的执行顺序。\n但是在JMM中是没有这个规定的，就是说其他线程看到执行顺序与除自己外的线程看到的执行顺序可能是不一致的。\n比如，当前线程把写过的数据缓存缓存到写缓存中，在没有刷新到主内存（计算机系统的DRAM）之前，这个写操作对其他线程是不可见的，意味着其他线程认为该线程根本没有执行写操作。\n那么何时才能可见呢？只有在当前线程把写缓存中数据刷新到主内存的时候，对其他内存才是可见的。\n```\n\n**如何控制多线程的执行顺序**？\n\n## 引用\n[多线程-重排序与顺序一致性](https://blog.csdn.net/hello_worldee/article/details/77823426)\n![[并发编程以及锁.pptx]]![[java多线程相关分享.pptx]]\n\n","tags":["多线程","jvm"],"categories":["java"]},{"title":"线程池实现原理","url":"/2022/01/14/线程池实现原理/","content":"\n## 线程池是什么\n线程池（Thread Pool）是一种基于==池化==思想管理线程的工具，经常出现在多线程服务器中，如MySQL。\n线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。\n\n## 线程池解决的问题是什么\n线程池解决的核心问题就是资源管理问题。在并发环境下，系统不能够确定在任意时刻中，有多少任务需要执行，有多少资源需要投入。这种不确定性将带来以下若干问题：\n1.  频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。\n2.  对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。\n3.  系统无法合理管理内部的资源分布，会降低系统的稳定性。\n为解决资源分配这个问题，线程池采用了“==池化==”（Pooling）思想。池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。\n>Pooling is the grouping together of resources (assets, equipment, personnel, effort, etc.) for the purposes of maximizing advantage or minimizing risk to the users. The term is used in finance, computing and equipment management.——wikipedia\n\n“池化”思想不仅仅能应用在计算机领域，在金融、设备、人员管理、工作管理等领域也有相关的应用。\n在计算机领域中的表现为：统一管理IT资源，包括服务器、存储、和网络资源等等。通过共享资源，使用户在低投入中获益。除去线程池，还有其他比较典型的几种使用策略包括：\n1.  内存池(Memory Pooling)：预先申请内存，提升申请内存速度，减少内存碎片。\n2.  连接池(Connection Pooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。\n3.  实例池(Object Pooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。\n\n## 线程池核心设计与实现\n在前文中，我们了解到：线程池是一种通过“池化”思想，帮助我们管理线程而获取并发性的工具，在Java中的体现是ThreadPoolExecutor类。\n\n\n## 线程池在业务中的实践\n**场景1：快速响应用户请求**\n**场景2：快速处理批量任务**\n\n## 引用\n[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)\n[Java并发编程：线程池的使用](https://www.cnblogs.com/xiaoxi/p/7692250.html)\n\n","tags":["线程池"],"categories":["java"]},{"title":"同步注解与并发性标注","url":"/2022/01/14/同步注解与并发性标注/","content":"\n## 同步注解\n\n- @GuardedBy( \"this\" ) 受对象内部锁保护\n- @GuardedBy( \"fieldName\" ) 受 与fieldName引用相关联的锁保护\n- @GuardedBy( \"ClassName.fieldName\" ) 受一个类的静态field的锁保护。\n- @GuardedBy( \"methodName()\" ) 锁对象是 methodName() 方法的返值，受这个锁保护。\n- @GuardedBy( \"ClassName.class\" ) 受 ClassName类的直接锁对象保护。而不是这个类的某个实例的锁对象。\n\n## 并发性标注\n@GuardedBy @NotThreadSafe @ThreadSafe\n这三个类级别的标注可以描述类的线程安全保证性,属于类公开文档的一部分.它只是标注了该类是否是线程安全的,但实际上没法保证线程安全.\n-   @Immutable  \n    表示类是不可变得既是final修饰的,它是线程安全的\n-   @ThreadSafe  \n    类是线程安全的\n-   @NotThreadSafe  \n    类不是线程安全的，如果类未加任何注解，则不能确定是否线程安全，认为是非线程安全的\n\t\n## 引用\n[并发性标注](https://blog.csdn.net/u010870167/article/details/88059219)","tags":["Spring","多线程"],"categories":["Spring"]},{"title":"关闭线程池","url":"/2022/01/14/关闭线程池/","content":"\n## dubbo优雅关闭线程池\n-   shutDown：通知线程池启动有序关闭，执行线程池之前已经提交的任务，但是不再接受新的任务。调用shutDown后再提交任务将会抛出RejectedExecutionException异常。\n-   shutDownNow：尝试立即停止所有已经提交的任务，并会返回正在等待执行（未执行）的任务列表。shutDownNow通过向线程池中的线程发送一个中断请求而中止线程，如果线程池中运行了会抛出InterruptedException的程序，将会抛出一个InterruptedException。如过这个线程不能响应中断那么可能永远无法被终止。\n-   isTerminated：所有的任务都被关闭返回true，否则返回false。只有调用了shutDown或者shutDownNow，isTerminated才可能为true。\n-   awaitTermination(long timeout,TimeUnit unit)throws InterruptedException：阻塞当前线程\n\n```java\n  private static final Logger logger = LoggerFactory.getLogger(ExecutorUtil.class);\n    private static final ThreadPoolExecutor shutdownExecutor = new ThreadPoolExecutor(0, 1,\n            0L, TimeUnit.MILLISECONDS,\n            new LinkedBlockingQueue<Runnable>(100),\n            new NamedThreadFactory(\"Close-ExecutorService-Timer\", true));\n\n    public static boolean isTerminated(Executor executor) {\n        if (executor instanceof ExecutorService) {\n            if (((ExecutorService) executor).isTerminated()) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    /**\n     * Use the shutdown pattern from:\n     *  https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html\n     * @param executor the Executor to shutdown\n     * @param timeout the timeout in milliseconds before termination\n     */\n    public static void gracefulShutdown(Executor executor, int timeout) {\n        if (!(executor instanceof ExecutorService) || isTerminated(executor)) {\n            return;\n        }\n        final ExecutorService es = (ExecutorService) executor;\n        try {\n            // Disable new tasks from being submitted\n            es.shutdown();\n        } catch (SecurityException ex2) {\n            return;\n        } catch (NullPointerException ex2) {\n            return;\n        }\n        try {\n            // Wait a while for existing tasks to terminate\n            if (!es.awaitTermination(timeout, TimeUnit.MILLISECONDS)) {\n                es.shutdownNow();\n            }\n        } catch (InterruptedException ex) {\n            es.shutdownNow();\n            Thread.currentThread().interrupt();\n        }\n        if (!isTerminated(es)) {\n            newThreadToCloseExecutor(es);\n        }\n    }\n\n    public static void shutdownNow(Executor executor, final int timeout) {\n        if (!(executor instanceof ExecutorService) || isTerminated(executor)) {\n            return;\n        }\n        final ExecutorService es = (ExecutorService) executor;\n        try {\n            es.shutdownNow();\n        } catch (SecurityException ex2) {\n            return;\n        } catch (NullPointerException ex2) {\n            return;\n        }\n        try {\n            es.awaitTermination(timeout, TimeUnit.MILLISECONDS);\n        } catch (InterruptedException ex) {\n            Thread.currentThread().interrupt();\n        }\n        if (!isTerminated(es)) {\n            newThreadToCloseExecutor(es);\n        }\n    }\n\n    private static void newThreadToCloseExecutor(final ExecutorService es) {\n        if (!isTerminated(es)) {\n            shutdownExecutor.execute(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        for (int i = 0; i < 1000; i++) {\n                            es.shutdownNow();\n                            if (es.awaitTermination(10, TimeUnit.MILLISECONDS)) {\n                                break;\n                            }\n                        }\n                    } catch (InterruptedException ex) {\n                        Thread.currentThread().interrupt();\n                    } catch (Throwable e) {\n                        logger.warn(e.getMessage(), e);\n                    }\n                }\n            });\n        }\n    }\n}\n```\n\n## 引用\n[学习dubbo如何优雅关闭线程池](https://developer.aliyun.com/article/756816)","tags":["线程池"],"categories":["java"]},{"title":"Empty List","url":"/2022/01/14/返回空List的几种方式/","content":"\n## 返回空List的方式\n\n1.  `new ArrayList()`\n2.  `new ArrayList(0)`\n3.  `Collections.emptyList()`\n4.  `Lists.newArrayList()`\n\n[返回空List的方式](https://blog.csdn.net/yangguosb/article/details/84573635)\n\n因为返回空集合的替代方法通常是返回null;\n然后呼叫者必须添加针对NullPointerException的警卫。如果返回空集合，则会减轻错误类别。在Java 8+中，还有一个Optional类型，它可以在没有Collection的情况下实现相同的目的。\n## 返回null 还是 空集合？ 推荐空集合\nnull ?? []\n**返回null 还是 空对象？**\n如果您打算指示没有可用数据，则返回null通常是最好的主意。\n**空对象表示已返回数据，而返回null则表示未返回任何内容。**\n\n此外，如果尝试访问**对象中的成员**，则返回null将会导致**null异常**，这对于突出显示错误代码很有用-尝试不访问任何成员是没有意义的。访问空对象的成员不会失败，这意味着错误可能会被发现。\nmap类似 Stream 的 map方法。处理完之后，返回的还是一个 Optional 对象，所以可以做链式调用。\n```java\nUser user = new User();\nString name = Optional.of(user).map(User::getName).orElse(\"佚名\");\nSystem.out.println(name);\n```\n如上，取出user对象的name值，若name为空，返回一个默认值“佚名”（神奇的名字）。\n这里，直接调用map方法，就不需要对user对象进行预先判空了。因为在map方法里边，会调用isPresent方法帮我们处理user为null的情况。\n到这里，脑袋转圈快的小伙伴，是不是对开头的坑已经有启发了。\n没错，我们可以通过 **Optional 的链式调用**，通过 map，orElse 等操作改写。如下，\n```java\nprivate static String getUserAddr1(Optional<User> user){\n    //先获取address对象\n    return user.map((u)->u.getAddress())\n            //再获取details值，\n            .map(e -> e.getDetails())\n            //若detail为null，则返回一个默认值\n            .orElse(\"地址信息未填写\");\n}\n```\n备注：[JDK8新特性](https://segmentfault.com/a/1190000023912618)","tags":["list","jdk","stream"],"categories":["java"]},{"title":"测试端口连通性","url":"/2022/01/14/测试端口连通性/","content":"\n## 如何测试端口通不通\n-   **使用telnet判断**\n\n`telnet ip post`\n\n-   **使用ssh判断**\n\n`ssh -v -p port username@ip`\n>-v 调试模式(会打印日志).\n>-p 指定端口\n>\n-   **使用wget判断**\n`wget ip:port`\n\n-  **使用端口扫描工具**\n-   **使用专用工具tcping进行访问：**\n\n## 引用\n[如何测试端口通不通](https://blog.csdn.net/swazer_z/article/details/64442730)","tags":["CentOS"],"categories":["Linux"]},{"title":"stream排序和分页","url":"/2022/01/14/Stream排序和分页/","content":"\n## Java 8 stream排序&分页\n\n### 排序\n\n```java\nList<Student newList = new ArrayList<>(10);\n//升序\nlist.stream().sorted((v1,v2)->v1.getId().compareTo(\n\tv2.getId()\n)).collect(Collectors.toList());\n\n//降序\nlist.stream().sorted((v1,v2)->v2getId().compareTo(\n\tv1.getId()\n)).collect(Collectors.toList());\n\n//根据子对象id，升序排序，Student对象中还有一个Boy的对象属性\nlist.stream().sorted((v1,v2)->v1.getBoy().getbId().compareTo(\n\tv2.getBoy().getbId()\n\t)).collect(Collectors.toList());\n```\n\n### 分页\n\n```java\nlist.stream().skip((currentPage-1)*pageSize).limit(pageSize).collect(Collectors.toList());\n```\n\n### 在项目中的运用：\n```java\nlong totalPage = resultList.size() / request.getPageSize() + (resultList.size() % request.getPageSize() > 0 ? 1 : 0);\nPagination pagination = new Pagination(request.getCurrent().longValue(), request.getPageSize().longValue(),(long) resultList.size(), totalPage);\n//通过stream对返回结果进行分页\nList<MarketingTaskEntity> paginationResults = resultList.stream().skip((request.getCurrent() - 1) * request.getPageSize()).limit(request.getPageSize()).collect(Collectors.toList());\n","tags":["stream"],"categories":["java"]},{"title":"SQL Where妙用","url":"/2022/01/14/SQL Where妙用/","content":"\n## 深入理解SQL中where 1=1的用处\n1. where 的条件为永真\nSQL注入时:\n`DELETE FROM table_a WHERE name= '张三'` \n`DELETE FROM table_a WHERE name= '张三' or 1=1` \n本来是删除ａ值为张三的这一条数据，这就又变成了无约束的删除了。\n1=1 永真， 1<>1 永假。\n\n2. 在后台写不定数量的查询条件下，便于规范语句，增加灵活性`String sql = \"select * from table a\";`\n\n**在不使用where 1=1的情况下**\n```java\nif(params.containsKey(\"name\")){\n    String key = params.get(\"name\").toString();\n    sql+=\"where a.name='\"+key +\"'\";\n}\nif(params.containsKey(\"age\")){\n    String key = params.get(\"age\").toString();\n    sql+=\"where a.age='\"+key +\"'\";\n}\nif(params.containsKey(\"class \")){\n    String key = params.get(\"class \").toString();\n    sql+=\"where a.class ='\"+key +\"'\";\n}\n```\n\n**当时用**where 1=1** 的时候**\n`String sql = \"select * from table a where 1=1\";`\n```java\nif(params.containsKey(\"name\")){\n    String key = params.get(\"name\").toString();\n    sql+=\" and a.name='\"+key +\"'\";\n}\nif(params.containsKey(\"age\")){\n    String key = params.get(\"age\").toString();\n    sql+=\" and a.age='\"+key +\"'\";\n}\nif(params.containsKey(\"class \")){\n    String key = params.get(\"class \").toString();\n    sql+=\" and a.class ='\"+key +\"'\";\n}\n```\n\n## Mybatis where 1=1 和 where标签\n```xml\n   <select id=\"selSampleListByIDX4\" resultMap=\"BaseResultMap\" parameterType=\"cn.com.git.cbs.datamodel.TBL_Sample\">\n    select \n    <include refid=\"Base_Column_List\" />\n    from SAMPLE\n    where 1=1   \n      <if test=\"samplenumber != null\" >\n        AND SAMPLENUMBER = #{samplenumber,jdbcType=DECIMAL}\n      </if>\n   </select> \n```\n\n Mybatis  之前拼条件的时候 写法  where 1=1，也可以使where标签\n```xml\n<select id=\"findActiveBlogLike\" resultType=\"Blog\">\n  SELECT * FROM BLOG \n  <where> \n    <if test=\"state != null\">\n         state = #{state}\n    </if> \n    <if test=\"title != null\">\n        AND title like #{title}\n    </if>\n    <if test=\"author != null and author.name != null\">\n        AND author_name like #{author.name}\n    </if>\n  </where>\n</select>\n```\n- where 元素知道只有在一个以上的if条件有值的情况下才去插入“WHERE”子句。而且，若最后的内容是“AND”或“OR”开头的，where 元素也知道如何将他们去除。\n- 如果 where 元素没有按正常套路出牌，我们还是可以通过自定义 trim 元素来定制我们想要的功能。比如，和 where 元素等价的自定义 trim 元素为：\n`<trim prefix=\"WHERE\" prefixOverrides=\"AND |OR \"> ... </trim>`\n\n## 参考\n[深入理解SQL中where 1=1的用处](https://blog.csdn.net/idomyway/article/details/78903822)\n[where 1=1有什么用](https://blog.csdn.net/qq_23994787/article/details/79045768)\n[where 1=1 和 where标签](https://blog.csdn.net/xiaxiaorui2003/article/details/53301540)","tags":["SQL"],"categories":["SQL"]},{"title":"SpringBoot参数校验","url":"/2022/01/14/SpringBoot参数校验/","content":"\n## 参数校验\n```java\n @ResponseBody\n @ExceptionHandler(MethodArgumentNotValidException.class)\n public BaseResponse argValidException(HttpServletResponse response, MethodArgumentNotValidException ex) {\n        logger.error(\"参数校验异常：\", ex);\n        StringBuilder builder = new StringBuilder();\n        if (ex.getBindingResult().hasErrors()) {\n            ex.getBindingResult().getFieldErrors().forEach(err->{\n                builder.append(err.getDefaultMessage()).append(\"\\n\");\n            });\n        }\n        return BaseResponse.fail(builder.toString());\n    }\n\n @RequestMapping(value = \"/apply/collection\", method = {RequestMethod.POST})\n    @ResponseBody\n    public BaseResponse applyCollectionPermission(@Valid @RequestBody ApplyCollectionPermissionRequest request) {\n        boolean success = metabaseService.applyCollection(request);\n        return success ? BaseResponse.success(\"已提交申请，等待审批。\") : BaseResponse.fail(\"操作失败，请重试\");\n    }\n\n@Getter\n@Setter\npublic class ApplyCollectionPermissionRequest {\n    @NotBlank(message = \"申请理由不能为空\")\n    String reason;\n    List<MBCollection> collections;\n}\n```\n\n## 引用\n[springboot使用hibernate validator](https://www.cnblogs.com/mr-yang-localhost/p/7812038.html)\n[@valid和@validated](https://juejin.cn/post/6844903974257049608)\n[分组校验](https://my.oschina.net/u/3706132/blog/1557940)","tags":["SpringBoot"],"categories":["Spring"]},{"title":"Redis锁","url":"/2022/01/14/Redis锁/","content":"\n## 项目应用\n```java\n//如果不存在(为空)就set值，并返回1；如果存在(不为空)不进行操作，并返回0\nBoolean success = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, String.valueOf(System.currentTimeMillis()), seconds, TimeUnit.SECONDS);\nreturn success != null && success;\n```\n\n## 引用\n[Redis分布式锁原理](https://xie.infoq.cn/article/556aaceb68789b9de4807f1c2)\n[Redis实现分布式锁](https://juejin.cn/post/6901484610031452174)\n[企业级分布式锁](https://blog.csdn.net/amosjob/article/details/99681707)","tags":["redis","分布式锁"],"categories":["缓存"]},{"title":"Presto引擎","url":"/2022/01/14/Presto引擎/","content":"\n## Presto数据模型\n\nPresto使用Catalog、Schema和Table这3层结构来管理数据。\n>** Catalog**:就是数据源。Hive是数据源，Mysql也是数据源，Hive 和Mysql都是数据源类型，可以连接多个Hive和多个Mysql，每个连接都有一个名字。一个Catalog可以包含多个Schema，大家可以通过show catalogs 命令看到Presto连接的所有数据源。\n>** Schema**：相当于一个数据库实例，一个Schema包含多张数据表。show schemas from 'catalog_name'可列出catalog_name下的所有schema。\n> **Table**：数据表，与一般意义上的数据库表相同。show tables from 'catalog_name.schema_name'可查看'catalog_name.schema_name'下的所有表。\n\n> 在Presto中定位一张表，一般是catalog为根，例如：一张表的全称为 hive.test_data.test，标识 hive(catalog)下的 test_data(schema)中test表。可以简理解为：数据源的大类.数据库.数据表。\n\n## 引用\n[Presto入门介绍](http://blog.chinaunix.net/uid-31012107-id-5819785.html)\n[Presto数据源](https://www.alibabacloud.com/help/zh/doc-detail/166150.htm)\n[Presto查询引擎及原理分析](https://cloud.tencent.com/developer/article/1630733)\n\n\n\n","tags":["presto"],"categories":["大数据"]},{"title":"MySQL执行计划","url":"/2022/01/14/MySQL执行计划/","content":"\n## `Explain` 用途\n1.  表的读取顺序如何\n2.  数据读取操作有哪些操作类型\n3.  哪些索引可以使用\n4.  哪些索引被实际使用\n5.  表之间是如何引用\n6.  每张表有多少行被优化器查询\n\n## `Explain`语法\n```sql\nexplain select * from user\n```\n\n\n## 引用\n[MySQL查询优化之explain 执行计划](https://blog.csdn.net/Dreamhai/article/details/104558854)","tags":["mysql"],"categories":["数据库"]},{"title":"Mybatis转义字符","url":"/2022/01/14/Mybatis转义字符/","content":"\n## 转义字符\n| 字符 | 转义       | 描述     |\n| ---- | ---------- | -------- |\n| <    | `&lt;`     | 小于     |\n| <=   | `&lt;=`    | 小于等于 |\n| >    | `&gt;`     | 大于     |\n| >=   | `&gt;=`    | 大于等于 |\n| <>   | `&lt;&gt;` | 不等于   |\n| &    | `&amp;`    |          |\n| '    | `&apos`    |          |\n| ''   | `&qots`    |          |\n\n此外，也可以用CDATA标志\n`<![CDATA[ 这里写你的sql ]]>`\n","tags":["mybatis"],"categories":["ORM"]},{"title":"List按照对象属性去重","url":"/2022/01/14/List按照对象属性去重/","content":"\n## 通过stream去重\n\n```java\npublic List getFileDetailList() {\nif (CollectionUtils.isNotEmpty(fileDetailList)) {\nreturn fileDetailList.stream().filter(distinctByKey(SecurityResource::getName)).collect(Collectors.toList());\n}\nreturn new ArrayList<>();\n}\n\nprivate static <T> Predicate<T> distinctByKey(Function<? super T, Object> keyExtractor) {\n    Map<Object, Boolean> seen = new ConcurrentHashMap<>(2 >> 4);\n    return t -> seen.putIfAbsent(keyExtractor.apply(t), Boolean.TRUE) == null;\n}\n```","tags":["list","jdk","stream"],"categories":["java"]},{"title":"JS基础语法","url":"/2022/01/14/JS基础语法/","content":"\n## Javascript中!!的含义\nJavascript中!!(两个感叹号，双感叹号)可以用来做什么，可以做出如下判断：\n-   数值：表示不是0，且有确定含义的值（包括无穷大）\n-   字符串：表示长度大于0的字符串\n-   数组，对象，函数：只能表示不是undefined或null,并不能判断是否有元素和内容。\n`if(!!arr && arr.length>0)`\n\n## js判断为空Null与字符串为空简写方法\n```javascript\nif (variable1 !== null || variable1 !== undefined || variable1 !== '') { \n \t var variable2 = variable1; \n  }\n```\n上面的意思是说如果variable1不是一个空对象，或者未定义，或者不等于空字符串，那么声明一个variable2变量，将variable1赋给variable2。也就是说如果variable1存在那么就将variable1的值赋给variable2，若不存在则为空字符串。如下面的简写代码。\n`var variable2 = variable1 || '';`\n判断字符串是否为空：\n`str.length==0`\n如果用户输入的是空格，制表符，换页符呢?这样的话，是不为空的\n可以用正则表达式来判断\n`str.replace(/(^s*)|(s*$)/g, \"\").length ==0`\n或者\n`str.replace(/(^\\s*)|(\\s*$)/g, \"\")) != \"\"`\n\n## 引用\n[js判空](https://www.cnblogs.com/daysme/p/6979231.html)","tags":["javascript"],"categories":["前端"]},{"title":"JSON序列化","url":"/2022/01/14/json序列化/","content":"\n## 属性序列化\n\n###  一、jackson的@JsonProperty使用\n\n```xml\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>2.5.3</version>\n</dependency>\n```\n@JsonProperty 此注解用于属性上，作用是把该属性的名称序列化为另外一个名称，如把trueName属性序列化为name，\n```java\n@JsonProperty(value=\"name\")。\nprivate String name;\n@JsonProperty(\"screen_name\")\nprivate String screen;\n```\n\n### 二、fastjson的@JSONField使用\n\n```xml\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>fastjson</artifactId>\n    <version>1.2.28</version>\n</dependency>\n```\n```java\n@JSONField(name=\"screen_name\")\nprivate String screen;\n```\n\n## 忽略属性\n### 一、jackson的JsonIgnore\n1.  作用：在json序列化时将java bean中的一些属性忽略掉，序列化和反序列化都受影响。\n2.  使用方法：一般标记在属性或者方法上，返回的json数据即不包含该属性。\n\n### 二、fastjson的@JSONField(serialize = false)\n\n\n## 日期格式化\n```java\n@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")  \n@JsonFormat(shape = JsonFormat.Shape.STRING, pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\")\nprivate LocalDateTime startTime;\n```\n\n@DatetimeFormat\norg.springframework.format.annotation.DateTimeFormat\n是将String转换成LocalDateTime，一般前台给后台传值时用\n\n@JsonFormat：com.fasterxml.jackson.annotation.JsonFormat\n将LocalDateTime转换成String  一般后台传值给前台时用\n\n","tags":["json"],"categories":["Spring"]},{"title":"Joiner简化用分隔符连接字符串序列","url":"/2022/01/14/Guava之Joiner/","content":"\n## `Joiner` 简化用分隔符连接字符串序列\n\n-   如果序列中包含 `null` 值，那么可以使用 `Joiner` 跳过 `null` 值：\n```java\n// 跳过 null 值\nresult = Joiner.on(\"; \").skipNulls().join(\"Harry\", null, \"Ron\", \"Hermione\");\nAssert.assertEquals(result, \"Harry; Ron; Hermione\");\n```\n- 也可以通过 `useForNull(String)` 来将 `null` 值替换为指定的字符串。\n```java\n// 替换 null 值\nresult = Joiner.on(\"; \").useForNull(\"null\").join(\"Harry\", null, \"Ron\", \"Hermione\");\nAssert.assertEquals(result, \"Harry; null; Ron; Hermione\");\n```\n-   同样可以在对象上使用 `Joiner`,最终会调用对象的 `toString()` 方法。\n```java\n// 使用在对象上，会调用对象的 toString() 函数\nresult = Joiner.on(\",\").join(Arrays.asList(1, 5, 7));\nAssert.assertEquals(result, \"1,5,7\");\n```\n-   对于 `Map` ,可以使用这样的代码：\n```java\n// MapJoiner 的使用，将 map 转换为字符串\nMap map = ImmutableMap.of(\"k1\", \"v1\", \"k2\", \"v2\");\nresult = Joiner.on(\"; \").withKeyValueSeparator(\"=\").join(map);\nAssert.assertEquals(result, \"k1=v1; k2=v2\");\n```","tags":["guava","字符串"],"categories":["java"]},{"title":"Guava中本地缓存LoadingCache使用","url":"/2022/01/14/Guava中本地缓存LoadingCache使用/","content":"## Guava Cache\n```md\n`Cache` 在实际场景中有着非常广泛的使用，通常情况下如果遇到需要大量时间计算或者获取值的场景，\n就应当将值保存到缓存中。`Cache` 和 `ConcurrentMap` 类似，但又不尽相同。\n最大的不同是 `ConcurrentMap` 会永久的存储所有的元素值直到他们被显示的移除，\n但是 `Cache` 会为了保持内存使用合理，而配置自动将一些值移除。\n```\n通常情况下，Guava Cache 适用于以下场景：\n-   花费一些内存来换取速度\n-   一些 key 会被不止一次被调用\n-   缓存内容有限，不会超过内存空间的值，Guava Cache 不会存储内容到文件或者到服务器外部，如果有此类需求考虑使用 Memcached, Redis 等类似工具\n先来看一下 Guava 中 Cache 接口的定义：\n```\ncom.google.common.cache.Cache\ncom.google.common.cache.Cache#asMap\ncom.google.common.cache.Cache#cleanUp\ncom.google.common.cache.Cache#get\ncom.google.common.cache.Cache#getAllPresent\ncom.google.common.cache.Cache#getIfPresent\ncom.google.common.cache.Cache#invalidate\ncom.google.common.cache.Cache#invalidateAll()\ncom.google.common.cache.Cache#invalidateAll(java.lang.Iterable<?>)\ncom.google.common.cache.Cache#put\ncom.google.common.cache.Cache#putAll\ncom.google.common.cache.Cache#size\ncom.google.common.cache.Cache#stats\n```\nCache 接口定义的方法大都一目了然，值得一说的就是 `stats()` 方法，这个方法会返回一个 `CacheStats` 对象，这个对象包括了该 Cache 的一些统计信息，包括 `hitCount`， `missCount`，`loadSuccessCount`，`loadExceptionCount`，`totalLoadTime` 和 `evictionCount`。\n`Cache` 通过 `CacheBuilder` 类的 Builder 模式获取：\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()\n       .maximumSize(1000)\n       .expireAfterWrite(10, TimeUnit.MINUTES)\n       .removalListener(MY_LISTENER)\n       .build(\n           new CacheLoader<Key, Graph>() {\n             public Graph load(Key key) throws AnyException {\n               return createExpensiveGraph(key);\n             }\n           });\n```\n\n如果使用的场景中对应着 key 的值有默认的值，那么可以选择使用 `CacheLoader`，如果没有默认值，那么仍然可以原子的 `get-if-absent-compute` 方法，在 `get` 方法中提供一个 `Callable`，或者元素也可以通过 `Cache.put` 来直接插入到缓存中。\n\n## LoadingCache\n```md\n`LoadingCache` 是一个附加着 `CacheLoader` 的 Cache。\n`LoadingCache<K,V>` 在 Guava 中是一个 interface，\n通常是用来本地 Cache 缓存 k-v 数据，value 会一直保存在内存中直到被移除或者失效。\n实现这个接口的类期望是线程安全的，能够安全的在多线程程序中被访问。\n```\n### LoadingCache 不能 Cache null\nLoadingCache 是不支持缓存 null 值的，如果 load 回调方法返回 null，则在 get 的时候会抛出异常。\n如果在 CacheLoader 中抛出异常，那么 Cache 会认为没有完成，所以新的值不会被 Cache。基于这一条规则，那么如何避免在 CacheLoader 中因为缓存 null 而抛出异常，那就是编程者自己处理 null 异常\n\n### get() vs getUnchecked()\n最正统的查询 `LoadingCache` 的方法是调用 `get(k)` 方法，这个方法如果查询到已经缓存的值会立即返回，否则使用缓存的 `CacheLoader` 自动加载一个新值到缓存并返回。因为 `CacheLoader` 可能会抛出异常，那么如果有异常，则`LoadingCache.get(k)` 会抛出 `ExecutionException` 异常。而如果 CacheLoader 抛出 unchecked 未检查的异常，则 `get(k)` 方法会抛出 `UncheckedExecutionException` 异常。\n此时可以选择使用 `getUnchecked(k)` 方法，这个方法会将所有的异常包装在 UncheckedExecutionException 异常中。需要注意的是，如果 CacheLoader 声明了检查异常，也就是 CacheLoader 显式的定义了异常，就不能调用 `getUnchecked(k)` 方法\n\n### 定时回收\nCacheBuilder 在构建 Cache 时提供了两种定时回收的方法\n-  expireAfterAccess(long, TimeUnit) : 缓存项在给定时间内没有被读或写访问，则回收\n-  expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收\n\n### 失效\n调用 LoadingCache 的 `invalidate` 方法可以使得 key 失效\n\n## 引用\n[guava wiki](https://github.com/google/guava/wiki/CachesExplained)\n[微服务缓存之Guava Cache](https://www.jianshu.com/p/2d3d30015915)","tags":["guava","缓存"],"categories":["缓存"]},{"title":"Hive实战","url":"/2020/12/28/Hive 实操/","content":"\n## 一、Database\n\n### 1.1 查看数据库列表\n\n```sql\nshow databases;\n```\n\n![image-20200902204156290](https://img.jinguo.tech/typora/image-20200902204156290.png?imageslim)\n\n### 1.2 查看数据库列表\n\n```sql\nuse database_name;\n```\n\n![image-20200902204350677](https://img.jinguo.tech/typora/image-20200902204350677.png?imageslim)\n\n### 1.3 新建数据库\n\n- 语法\n\n  ```sql\n  CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name   --DATABASE|SCHEMA 是等价的\n    [COMMENT database_comment] --数据库注释\n    [LOCATION hdfs_path] --存储在 HDFS 上的位置\n    [WITH DBPROPERTIES (property_name=property_value, ...)]; --指定额外属性\n  ```\n\n- 示例\n\n  ```sql\n  CREATE DATABASE IF NOT EXISTS hive_test\n    COMMENT 'hive database for test'\n    WITH DBPROPERTIES ('create'='jinguo');\n  ```\n\n  ![image-20200902203705654](https://img.jinguo.tech/typora/image-20200902203705654.png?imageslim)\n\n### 1.4 查看数据库信息\n\n- 语法：\n\n```sql\nDESC DATABASE [EXTENDED] db_name; --EXTENDED 表示是否显示额外属性\n```\n\n- 示例：\n\n```sql\nDESC DATABASE  EXTENDED hive_test;\n```\n\n![image-20200903100904811](https://img.jinguo.tech/typora/image-20200903100904811.png?imageslim)\n\n### 1.5 删除数据库\n\n语法：\n\n```sql\nDROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];\n```\n\n*默认行为是 **RESTRICT**，如果数据库中存在表则删除失败。要想删除库及其中的表，可以使用 **CASCADE** 级联删除。*\n\n示例：\n\n```sql\n  DROP DATABASE IF EXISTS hive_test;\n```\n\n![image-20200903111952592](https://img.jinguo.tech/typora/image-20200903111952592.png?imageslim)\n\n```verilog\nError while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database hive_test is not empty. One or more tables exist.)\n```\n\n*当数据库中存在表的时候，删除时需要用**CASCADE***关键字\n\n```sql\nDROP DATABASE IF EXISTS hive_test CASCADE;\n```\n\n![image-20200903112539723](https://img.jinguo.tech/typora/image-20200903112539723.png?imageslim)\n\n## 二、创建表\n\n### 2.1 建表语法\n\n- 语法\n\n```sql\nCREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name     --表名\n  [(col_name data_type [COMMENT col_comment],\n    ... [constraint_specification])]  --列名 列数据类型\n  [COMMENT table_comment]   --表描述\n  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]  --分区表分区规则\n  [\n    CLUSTERED BY (col_name, col_name, ...) \n   [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS\n  ]  --分桶表分桶规则\n  [SKEWED BY (col_name, col_name, ...) ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)  \n   [STORED AS DIRECTORIES] \n  ]  --指定倾斜列和值\n  [\n   [ROW FORMAT row_format]    \n   [STORED AS file_format]\n     | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  \n  ]  -- 指定行分隔符、存储文件格式或采用自定义存储格式\n  [LOCATION hdfs_path]  -- 指定表的存储位置\n  [TBLPROPERTIES (property_name=property_value, ...)]  --指定表的属性\n  [AS select_statement];   --从查询结果创建表\n```\n\n### 2.2 创建内部表\n\n- 示例\n\n```sql\n CREATE TABLE emp(\n    empno INT,\n    ename STRING,\n    job STRING,\n    mgr INT,\n    hiredate TIMESTAMP,\n    sal DECIMAL(7,2),\n    comm DECIMAL(7,2),\n    deptno INT)\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \"\\t\";\n```\n\n![image-20200903180953529](https://img.jinguo.tech/typora/image-20200903180953529.png?imageslim)\n\n### 2.3 创建外部表\n\n- 示例\n\n```sql\n CREATE EXTERNAL TABLE emp_external(\n    empno INT,\n    ename STRING,\n    job STRING,\n    mgr INT,\n    hiredate TIMESTAMP,\n    sal DECIMAL(7,2),\n    comm DECIMAL(7,2),\n    deptno INT)\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \"\\t\"\n    LOCATION '/hive/emp_external';\n```\n\n![image-20200903181743473](https://img.jinguo.tech/typora/image-20200903181743473.png?imageslim)\n\n*用**DESC TABLENAME**查看表格信息*\n\n![image-20200903184628794](https://img.jinguo.tech/typora/image-20200903184628794.png?imageslim)\n\n*用**DESC FORMATTED TABLENAME**命令可以查看表的详细信息*\n\n![image-20200903190348379](https://img.jinguo.tech/typora/image-20200903190348379.png?imageslim)\n\n*通过**hdfs dfs -ls**命令可以看到Location的外部表已经存在*\n\n![image-20200903185141700](https://img.jinguo.tech/typora/image-20200903185141700.png?imageslim)\n\n\n\n### 2.4 内部表和外部表区别\n\n**创建表时**\n\n- 创建内部表：会将数据移动到数据仓库指向的路径；\n- 创建外部表：仅记录数据所在的路径， 不对数据的位置做任何改变。\n\n**删除表时**\n\n- 内部表的元数据和数据会被一起删除\n- 外部表只删除元数据，不删除数据。外部表相对来说更加安全，数据组织更加灵活，方便共享源数据。\n\n**总结：**\n\n1. 未被external修饰的是内部表【*managed table*】，被external修饰的为外部表【*external table*】。\n\n2. 内部表数据由Hive自身管理，外部表数据由HDFS管理。\n\n3. 内部表数据存储在*hive.metastore.warehouse.dir*【默认:*/user/hive/warehouse*】，外部表数据存储位置由用户自己决定。如 *location '/hive/emp_external'*\n\n   ![image-20200904222601364](https://img.jinguo.tech/typora/image-20200904222601364.png?imageslim)\n\n   ![image-20200904222820733](https://img.jinguo.tech/typora/image-20200904222820733.png?imageslim)\n\n4. 删除内部表会直接删除元数据【*metadata*】及**存储数据**，删除外部表仅仅删除元数据，*HDFS*上的文件不会被删除。\n5. 对内部表的修改会直接同步到元数据，而对外部表的表结构和分区进行修改，则需要修改【*MSCK REPAIR TABLE table_name*】。\n\n### 2.5 创建分区表\n\n- 示例\n\n``` sql\n CREATE EXTERNAL TABLE emp_partition(\n    empno INT,\n    ename STRING,\n    job STRING,\n    mgr INT,\n    hiredate TIMESTAMP,\n    sal DECIMAL(7,2),\n    comm DECIMAL(7,2)\n    )\n    PARTITIONED BY (deptno INT)  -- 按照部门编号进行分区\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \"\\t\"\n    LOCATION '/hive/emp_partition';\n```\n\n![image-20200903191518107](https://img.jinguo.tech/typora/image-20200903191518107.png?imageslim)\n\n*用**DESC TABLENAME**查看表格信息*\n\n![image-20200903193011185](https://img.jinguo.tech/typora/image-20200903193011185.png?imageslim)\n\n*用**DESC FORMATTED TABLENAME**命令可以查看表的详细信息*\n\n![image-20200903192022966](https://img.jinguo.tech/typora/image-20200903192022966.png?imageslim)\n\n*通过**hdfs dfs -ls**命令可以看到Location的外部表已经存在*\n\n![image-20200903191648232](https://img.jinguo.tech/typora/image-20200903191648232.png?imageslim)\n\n### 2.6 分桶表\n\n- 示例\n\n```sql\n CREATE EXTERNAL TABLE emp_bucket(\n    empno INT,\n    ename STRING,\n    job STRING,\n    mgr INT,\n    hiredate TIMESTAMP,\n    sal DECIMAL(7,2),\n    comm DECIMAL(7,2),\n    deptno INT)\n    CLUSTERED BY(empno) SORTED BY(empno ASC) INTO 4 BUCKETS  --按照员工编号散列到四个 bucket 中\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \"\\t\"\n    LOCATION '/hive/emp_bucket';\n```\n\n![image-20200903192305213](https://img.jinguo.tech/typora/image-20200903192305213.png?imageslim)\n\n*用**DESC TABLENAME**查看表格信息*\n\n![image-20200903192644607](https://img.jinguo.tech/typora/image-20200903192644607.png?imageslim)\n\n*用**DESC FORMATTED TABLENAME**命令可以查看表的详细信息*![image-20200903192505630](https://img.jinguo.tech/typora/image-20200903192505630.png?imageslim)\n\n*通过**hdfs dfs -ls**命令可以看到Location的外部表已经存在*\n\n![image-20200903192829644](https://img.jinguo.tech/typora/image-20200903192829644.png?imageslim)\n\n### 2.7 倾斜表\n\n*通过指定一个或者多个列经常出现的值（严重偏斜），**Hive**会自动将涉及到这些值的数据拆分为单独的文件。在查询时，如果涉及到倾斜值，它就直接从独立文件中获取数据，而不是扫描所有文件，这使得性能得到提升*\n\n- 示例\n\n``` sql\n CREATE EXTERNAL TABLE emp_skewed(\n    empno INT,\n    ename STRING,\n    job STRING,\n    mgr INT,\n    hiredate TIMESTAMP,\n    sal DECIMAL(7,2),\n    comm DECIMAL(7,2)\n    )\n    SKEWED BY (empno) ON (66,88,100)  --指定 empno 的倾斜值 66,88,100\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \"\\t\"\n    LOCATION '/hive/emp_skewed';   \n```\n\n![image-20200903193642678](https://img.jinguo.tech/typora/image-20200903193642678.png?imageslim)","tags":["Hive"],"categories":["大数据"]},{"title":"storm心得-下","url":"/2020/08/06/storm心得-下/","content":"\n## dubbo的引入\n\n随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进\n![mark](https://img.jinguo.tech/blog/20200116/wjl7jTS7zaLL.png?imageslim)\n\n- 单一应用架构\n  当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。  \n  此时，用于简化增删改查工作量的  数据访问框架(ORM)  是关键。  \n\n- 垂直应用架构\n  当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。  \n  此时，用于加速前端页面开发的  Web框架(MVC)  是关键。  \n\n- 分布式服务架构\n  当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。  \n  此时，用于提高业务复用及整合的  分布式服务框架(RPC)  是关键。  \n\n- 流动计算架构\n  当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率  \n  此时，用于提高机器利用率的  资源调度和治理中心(SOA)  是关键。  \n\n  \n\n在大规模服务化之前，应用可能只是通过RMI或Hessian等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过F5等硬件进行负载均衡。  \n\n1. 当服务越来越多时，服务URL配置管理变得非常困难，F5硬件负载均衡器的单点压力也越来越大。  \n   此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和Failover，降低对F5硬件负载均衡器的依赖，也能减少部分成本。  \n2. 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。  \n   这时，需要自动画出应用间的依赖关系图，以理清理关系。  \n3. 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？  \n   为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。     \n   其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阀值，记录此时的访问量，再以此访问量乘以机器数反推总容量。  \n\n### Dubbo的工作原理\n\n![mark](https://img.jinguo.tech/blog/20200116/9BmbGSdmqAIw.png?imageslim)\n\n### 节点角色说明：\n\n- Provider:  暴露服务的服务提供方。\n- Consumer:  调用远程服务的服务消费方。\n- Registry:  服务注册与发现的注册中心。\n- Monitor:  统计服务的调用次调和调用时间的监控中心。\n- Container:  服务运行容器。\n\n### 调用关系说明：\n\n- 服务容器负责启动，加载，运行服务提供者。\n- 服务提供者在启动时，向注册中心注册自己提供的服务。\n- 服务消费者在启动时，向注册中心订阅自己所需的服务。\n- 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\n- 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n- 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n\n## Dubbo-admin管理平台的安装\n\n### dubbo-admin 本地编译打包\n\nhttps://github.com/alibaba/dubbo/releases  \nhttps://github.com/apache/incubator-dubbo/releases  \n解压后，根目录里不存在dubbo-admin，无法编译打包，发现dubbo-admin迁移到新地址  \nhttps://github.com/apache/incubator-dubbo-ops\n\n### 克隆项目\n\napache 下的dubbo-admin git仓库：  \nhttps://github.com/apache/incubator-dubbo-ops  \n先把这个项目用git克隆到本地中  \n![mark](https://img.jinguo.tech/blog/20200116/K3cL9oIMDyUc.png?imageslim)\n\n#### application.properties配置\n\n![mark](https://img.jinguo.tech/blog/20200116/OBg6vOx9Hm2v.png?imageslim)\n\n#### application-test.properties配置\n\n![](https://ws1.sinaimg.cn/large/005Vjva3gy1g3a8nhcmhnj30tw04ujrj.jpg)\n\n#### tomcat配置启动项\n\n![mark](https://img.jinguo.tech/blog/20200116/jTIptyM29eyc.png?imageslim)\n\n#### 配置部署war包\n\n![mark](https://img.jinguo.tech/blog/20200116/pMWYodys0jHX.png?imageslim)  \n![mark](https://img.jinguo.tech/blog/20200116/815r6xyBFzgC.png?imageslim)\n\n#### 说明：可以发现最新版本的 dubbo-admin 为springboot项目，可以直接打包成jar，使用java -jar xxx.jar 运行。\n\n#### Production Setup\n\n1. Clone source code on develop branch git clone https://github.com/apache/incubator-dubbo-admin.git\n2. Specify registry address in dubbo-admin-server/src/main/resources/application.properties\n3. Build  \n   mvn clean package  \n   ![mark](https://img.jinguo.tech/blog/20200116/QW4o2Lu212cH.png?imageslim)\n4. Start  \n   mvn --projects dubbo-admin-server spring-boot:run  \n   **启动Zookeeper集群**\n   ![mark](https://img.jinguo.tech/blog/20200116/6S0qSXjElGrA.png?imageslim)  \n   ![mark](https://img.jinguo.tech/blog/20200116/KuguVid47fPC.png?imageslim)\n5. Visit http://localhost:8080\n   ![mark](https://img.jinguo.tech/blog/20200116/LvOOUrd9THDG.png?imageslim)\n\n### 报错1\n\n![mark](https://img.jinguo.tech/blog/20200116/Y5eggYkh3Rcn.png?imageslim)\n\n### 解决办法\n\n如果SpringBoot在子模块，直接main启动子模块会报错。\n解决办法就是在IDEA MAVEN Projects->dubbo-admin-server->Plugins->spring-boot->spring-boot:run->run maven build\n![mark](https://img.jinguo.tech/blog/20200116/3Ks7eNPV4RNd.png?imageslim)\n\n### 报错2\n\n![mark](https://img.jinguo.tech/blog/20200116/rbB1U2e6QnzT.png?imageslim)\n\n### 解决办法\n\ntaskkill /pid 8876 /f\n\n![mark](https://img.jinguo.tech/blog/20200116/C9aKSFeYcYUi.png?imageslim)\n\n## zookeeper与dubbo关系\n\ndubbo是动物园，动物园里有什么动物，有动物园自己说了算，zookeeper只是登记了园里有什么动物可供参观，游客可以参观那个动物，参观人数太多，ZK如何分流等，动物园可以不用ZK做这个工作（能提供这个功能的有很多），可以用别的做这个注册、选举、分流、负载均衡的管理工作，只是大家都用ZK；dubbo中的注册中心用了zookeeper而已，也可以用别的，dubbo有注册中心（使用了ZK）、服务提供者、消费者、运行容器，监视器；\n\n## Netty在Dubbo中的应用\n\n**Dubbo 底层使用的是 Netty 作为网络通信**  \n\n1. dubbo的Consumer消费者如何使用Netty  \n\n### 调用 Spring 容器的 getBean 方法, dubbo 扩展了 FactoryBean，所以，会调用 getObject 方法，该方法会创建代理对象。\n\n```java\n// get remote service proxy\nDemoService demoService = (DemoService) context.getBean(\"demoService\");\n```\n\n### 调用 DubboProtocol 实例的 getClients（URL url） 方法，当这个给定的 URL 的 client 没有初始化则创建，然后放入缓存  \n\n```java\nprivate ExchangeClient getSharedClient(URL url){\n\tString key=url.getAddress();\n\tReferenceCountExchangeClient client=referenceClientMap.get(key);\n\tif(client!=null){\n\t\tif(!=client.isClosed()){\n\t\t\tclient.incrementAndGetCount();\n\t\t\treturn client;\n\t\t}else{\n\t\t\treferenceClientMap.remove(key);\n\t\t}\n\t}\n\tsynchronized(key.intern()){\n\t\t//这个initClient()方法是创建Netty的client的\n\t\tExchangeClient exchangeClient=initClient(url);\n\t\tclient=new ReferenceCountExchangeClient(exchangeClient,ghostClientMap);\n\t\treferenceClientMap.put(key,client);\n\t\tghostClientMap.remove(key);\n\t\treturn client;\n\t}\n}\n```\n\n### 最终调用的就是抽象父类AbstractClient的构造方法，构造方法中包含了创建Socket客户端，连接客户端等行为。\n\n```java\npublic AbstractClient(URL url, ChannelHandler handler) throws RemotingException {\n    doOpen();\n    connect();\n}\n```\n\n### doOpent 方法用来创建 Netty 的 bootstrap ：\n\n```java\nprotected void doOpen() throws Throwable {\n    NettyHelper.setNettyLoggerFactory();\n    bootstrap = new ClientBootstrap(channelFactory);\n    bootstrap.setOption(\"keepAlive\", true);\n    bootstrap.setOption(\"tcpNoDelay\", true);\n    bootstrap.setOption(\"connectTimeoutMillis\", getTimeout());\n    final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n        public ChannelPipeline getPipeline() {\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            pipeline.addLast(\"decoder\", adapter.getDecoder());\n            pipeline.addLast(\"encoder\", adapter.getEncoder());\n            pipeline.addLast(\"handler\", nettyHandler);\n            return pipeline;\n        }\n    });\n}\n```\n\n### connect 方法用来连接提供者：\n\n```java\nprotected void doConnect() throws Throwable {\n    long start = System.currentTimeMillis();\n\t//调用了 bootstrap 的 connect 方法,这里使用的是 jboss 的 netty3,当连接成功后，注册写事件，准备开始向提供者传递数据。 \n    ChannelFuture future = bootstrap.connect(getConnectAddress());\n    boolean ret = future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS);\n    if (ret && future.isSuccess()) {\n        Channel newChannel = future.getChannel();\n        newChannel.setInterestOps(Channel.OP_READ_WRITE);\n    } \n}\n```\n\n### main 方法最终会调用 HeaderExchangeChannel 的 request 方法，通过 channel 进行请求。  \n\n```java\npublic ResponseFuture request(Object request, int timeout) throws RemotingException {\n    Request req = new Request();\n    req.setVersion(\"2.0.0\");\n    req.setTwoWay(true);\n    req.setData(request);\n    DefaultFuture future = new DefaultFuture(channel, req, timeout);\n\t//send 方法中最后调用 jboss Netty 中继承了 NioSocketChannel 的 NioClientSocketChannel 的 write 方法。完成了一次数据的传输。  \n    channel.send(req);\n    return future;\n}\n```\n\n## dubbo 的 Provider 提供者如何使用 Netty  \n\nProvider 作为被访问方，是一个 Server 模式的 Socket。 Spring 容器启动的时候，会调用一些扩展类的初始化方法，比如继承了  InitializingBean，ApplicationContextAware，ApplicationListener。而 dubbo 创建了 ServiceBean 继承了一个监听器。Spring 会调用他的 onApplicationEvent 方法，该类有一个 export 方法，用于打开 ServerSocket 。  然后执行了 DubboProtocol 的 createServer 方法，然后创建了一个 NettyServer 对象。\n\n### NettyServer 对象的构造方法同样是 doOpen 方法。\n\n```java\nprotected void doOpen() throws Throwable {\n    NettyHelper.setNettyLoggerFactory();\n\t//boss 线程，worker 线程，和 ServerBootstrap\n    ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerBoss\", true));\n    ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(\"NettyServerWorker\", true));\n    ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS));\n    bootstrap = new ServerBootstrap(channelFactory);\n\t//在添加了编解码 handler 之后，添加一个 NettyHandler，最后调用 bind 方法，完成绑定端口的工作。\n    final NettyHandler nettyHandler = new NettyHandler(getUrl(), this);\n    channels = nettyHandler.getChannels();\n    bootstrap.setPipelineFactory(new ChannelPipelineFactory() {\n        public ChannelPipeline getPipeline() {\n            NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this);\n            ChannelPipeline pipeline = Channels.pipeline();\n            pipeline.addLast(\"decoder\", adapter.getDecoder());\n            pipeline.addLast(\"encoder\", adapter.getEncoder());\n            pipeline.addLast(\"handler\", nettyHandler);\n            return pipeline;\n        }\n    });\n    channel = bootstrap.bind(getBindAddress());\n}\n```\n\n### Netty在Dubbo中的应用总结\n\ndubbo中消费者使用 NettyClient，提供者使用 NettyServer，Provider 启动的时候，会开启端口监听。Client 在 Spring getBean 的时候，会创建 Client。当调用远程方法的时候，将数据通过 dubbo 协议编码发送到 NettyServer，然后 NettServer 收到数据后解码，并调用本地方法，并返回数据，完成一次完美的 RPC 调用。\n\n## Apache Storm分布式消息系统\n\nApache Storm处理实时数据，并且输入通常来自消息排队系统。外部分布式消息系统将提供实时计算所需的输入。Spout将从消息系统读取数据，并将其转换为元组并输入到Apache Storm中。Apache Storm在内部使用其自己的分布式消息传递系统，用于其nimbus和主管之间的通信。  \n\n### 什么是分布式消息系统？  \n\n分布式消息传递基于可靠消息队列的概念。消息在客户端应用程序和消息系统之间异步排队。分布式消息传递系统提供可靠性，可扩展性和持久性的好处。  \n大多数消息模式遵循发布 - 订阅模型（简称发布 - 订阅），其中消息的发送者称为发布者，而想要接收消息的那些被称为订阅者。  \n一旦消息已经被发​​送者发布，订阅者可以在过滤选项的帮助下接收所选择的消息。通常我们有两种类型的过滤，一种是基于主题的过滤，另一种是基于内容的过滤。  \n需要注意的是，pub-sub模型只能通过消息进行通信。它是一个非常松散耦合的架构;甚至发件人不知道他们的订阅者是谁。许多消息模式使消息代理能够交换发布消息以便由许多订户及时访问。\n\n![mark](https://img.jinguo.tech/blog/20200116/lG6PiOTlO76X.png?imageslim)\n\n下表描述了一些流行的高吞吐量消息传递系统 -\n![mark](https://img.jinguo.tech/blog/20200116/LFSn4gj0zFXj.png?imageslim)\nThrift在Facebook上构建，用于跨语言服务开发和远程过程调用（RPC）。后来，它成为一个开源的Apache项目。Apache Thrift是一种接口定义语言，允许以容易的方式在定义的数据类型之上定义新的数据类型和服务实现。    \nApache Thrift也是一个支持嵌入式系统，移动应用程序，Web应用程序和许多其他编程语言的通信框架。与Apache Thrift相关的一些关键功能是它的模块化，灵活性和高性能。此外，它可以在分布式应用程序中执行流式处理，消息传递和RPC。  \nStorm广泛使用Thrift协议进行内部通信和数据定义。Storm拓扑只是Thrift Structs。在Apache Storm中运行拓扑的Storm Nimbus是一个Thrift服务。\n\n## Storm工作原理\n\n![mark](https://img.jinguo.tech/blog/20200116/79gVc35j1D9V.png?imageslim)\n\n### Storm与传统关系型数据库 \n\n传统关系型数据库是先存后计算，而storm则是先算后存，甚至不存   \n传统关系型数据库很难部署实时计算，只能部署定时任务统计分析窗口数据 \n关系型数据库重视事务，并发控制，相对来说Storm比较简陋   \nStorm与Hadoop，Spark等是流行的大数据方案    \n与Storm关系密切的语言：核心代码用clojure书写，实用程序用python开发，使用java开发拓扑  \n\n1. topology  \n   Storm集群中有两种组件节点，一种是**控制节点**(Nimbus节点)，另一种是**工作节点**(Supervisor节点)。这两种组件都是快速失败的，没有状态。任务状态和心跳信息等都保存在Zookeeper上的，提交的代码资源都在本地机器的硬盘上。所有Topology任务的 提交必须在Storm客户端节点上进行(需要配置 storm.yaml文件)，由Nimbus节点分配给其他Supervisor节点进行处理。 Nimbus负责在集群里面发送代码，分配工作给机器，并且监控状态。全局只有一个。Nimbus节点首先将提交的Topology进行分片，分成一个个的Task，并将Task和Supervisor相关的信息提交到 zookeeper集群上，Supervisor会去zookeeper集群上认领自己的Task，通知自己的Worker进程进行Task的处理。   \n   和同样是计算框架的MapReduce相比，MapReduce集群上运行的是Job，而Storm集群上运行的是Topology。但是Job在运行结束之后会自行结束，Topology却只能被手动的kill掉，否则会一直运行下去  \n   数据存储之后的展现，也是需要自己处理的，storm UI 只提供对topology的监控和统计。 \n   ![mark](https://img.jinguo.tech/blog/20200116/giIigvaTGzfK.png?imageslim)\n\n2. zookeeper集群  \n   storm使用zookeeper来协调整个集群， 但是要注意的是storm并不用zookeeper来传递消息。所以zookeeper上的负载是非常低的，单个节点的zookeeper在大多数情况下 都已经足够了， 但是如果你要部署大一点的storm集群， 那么你需要的zookeeper也要大一点。  \n   部署zookeeper有些需要注意的地方：  \n   ①对zookeeper做好监控非常重要， zookeeper是fail-fast的系统，只要出现什么错误就会退出， 所以实际场景中要监控   \n   ②实际场景中要配置一个cron job来压缩zookeeper的数据和业务日志。zookeeper自己是不会去压缩这些的，所以你如果不设置一个cron job, 磁盘会很快不够用\n\n3. Component\n   Storm中，Spout和Bolt都是Component。所以，Storm定义了一个名叫IComponent的总接口 \n    全家谱如下：绿色部分是我们最常用、比较简单的部分。红色部分是与事务相关的。\n   ![mark](https://img.jinguo.tech/blog/20200116/3ydBPi1GBWs0.png?imageslim)\n\n4. Spout\n   Spout是Stream的消息产生源， Spout组件的实现可以通过继承BaseRichSpout类或者其他Spout类来完成，也可以通过实现IRichSpout接口来实现\n\n   ```java\n   public interface ISpout extends Serializable { \n     void open(Map conf, TopologyContext context, SpoutOutputCollector collector); \n     void close(); \n     void nextTuple(); \n     void ack(Object msgId); \n     void fail(Object msgId); \n   }   \n   ```\n\n    ①open()方法 -- 初始化方法   \n    close() -- 在该spout将要关闭时调用。但是不保证其一定被调用，因为在集群中supervisor节点，可以使用kill -9来杀死worker进程。只有当Storm是在本地模式下运行，如果是发送停止命令，可以保证close的执行   \n    ②ack(Object msgId) -- 成功处理tuple时回调的方法，通常情况下，此方法的实现是将消息队列中的消息移除，防止消息重放   \n    ③fail(Object msgId) -- 处理tuple失败时回调的方法，通常情况下，此方法的实现是将消息放回消息队列中然后在稍后时间里重放   \n    ④nextTuple() -- 这是Spout类中最重要的一个方法。发射一个Tuple到Topology都是通过这个方法来实现的。调用此方法时，storm向spout发出请求，让spout发出元组（tuple）到输出器（ouput collector）。这种方法应该是非阻塞的，所以spout如果没有元组发出，这个方法应该返回。nextTuple、ack 和fail 都在spout任务的同一个线程中被循环调用。 当没有元组的发射时，应该让nextTuple睡眠一个很短的时间（如一毫秒），以免浪费太多的CPU。继承了BaseRichSpout后，不用实现close、 activate、 deactivate、 ack、 fail 和 getComponentConfiguration 方法，只关心最基本核心的部分。   通常情况下（Shell和事务型的除外），实现一个Spout，可以直接实现接口IRichSpout，如果不想写多余的代码，可以直接继承BaseRichSpout \n\n5. Bolt\n   Bolt类接收由Spout或者其他上游Bolt类发来的Tuple，对其进行处理。Bolt组件的实现可以通过继承BasicRichBolt类或者IRichBolt接口等来完成  \n     prepare方法 -- 此方法和Spout中的open方法类似，在集群中一个worker中的task初始化时调用。 它提供了bolt执行的环境   \n     declareOutputFields方法 -- 用于声明当前Bolt发送的Tuple中包含的字段(field)，和Spout中类似   \n     cleanup方法 -- 同ISpout的close方法，在关闭前调用。同样不保证其一定执行。   \n     execute方法 -- 这是Bolt中最关键的一个方法，对于Tuple的处理都可以放到此方法中进行。具体的发送是通过emit方法来完成的。execute接受一个tuple进行处理，并用prepare方法传入的  OutputCollector的ack方法（表示成功）或fail（表示失败）来反馈处理结果。   \n     Storm提供了IBasicBolt接口，其目的就是实现该接口的Bolt不用在代码中提供反馈结果了，Storm内部会自动反馈成功。如果你确实要反馈失败，可以抛出FailedException   \n     通常情况下，实现一个Bolt，可以实现IRichBolt接口或继承BaseRichBolt，如果不想自己处理结果反馈，可以实现 IBasicBolt接口或继承BaseBasicBolt，它实际上相当于自动实现了collector.emit.ack(inputTuple) \n\n6. Topology运行方式\n   在开始创建项目之前，了解Storm的操作模式(operation modes)是很重要的。 Storm有两种运行方式 \n\n### 本地运行的提交方式 \n\n```java\nLocalCluster cluster = new LocalCluster(); \ncluster.submitTopology(TOPOLOGY_NAME, conf, builder.createTopology()); \nThread.sleep(2000); \ncluster.shutdown(); \n```\n\n### 分布式提交方式\n\n```java\nStormSubmitter.submitTopology（TOPOLOGY_NAME, conf, builder.createTopology()); \n```\n\n  需要注意的是，在Storm代码编写完成之后，需要打包成jar包放到Nimbus中运行，打包的时候，不需要把依赖的jar都打迚去，否则如果把依赖的storm.jar包打进去的话，运行时会出现重复的配置文件错误导致Topology无法运行。因为Topology运行之前，会加载本地的 storm.yaml 配置文件。 \n\n### 运行的命令如下###\n\n```shell\nstorm jar StormTopology.jar mainclass [args] \n```\n\n## storm守护进程的命令\n\n  Nimbus: storm nimbus 启动nimbus守护进程   \n  Supervisor: storm supervisor 启动supervisor守护迚程   \n  UI：storm ui 这将启动stormUI的守护进程,为监测storm集群提供一个基于web的用户界面。  \n  DRPC: storm drpc 启动DRPC的守护进程  \n\n## storm管理命令\n\n```shell\nJAR：storm jar topology_jar topology_class [arguments...] \n```\n\njar命令是用于提交一个集群拓扑.它运行指定参数的topology_class中的main()方法，上传topology_jar到nimbus，由nimbus发布到集群中。一旦提交，storm将激活拓扑并开始处理topology_class 中的main()方法，main()方法负责调用StormSubmitter.submitTopology()方法，并提供一个唯一的拓扑(集群)的名。如果一个拥有该名称的拓扑已经存在于集群中，jar命令将会失败。常见的做法是在使用命令行参数来指定拓扑名称，以便拓扑在提交的时候被命名。 \n\n```shell\nKILL：storm kill topology_name [-w wait_time] \n```\n\n杀死一个拓扑，可以使用kill命令。它会以一种安全的方式销毁一个拓扑，首先停用拓扑，在等待拓扑消息的时间段内允许拓扑完成当前的数据流。执行kill命令时可以通过-w [等待秒数]指定拓扑停用以后的等待时间。也可以在Storm UI 界面上实现同样的功能 \n\n```shell\n Deactivate：storm deactivate topology_name \n```\n\n 停用拓扑时，所有已分发的元组都会得到处理，spouts的nextTuple方法将不会被调用。也可以在Storm UI 界面上实现同样的功能 \n\t\n\n```shell\n  Activate：storm activate topology_name \n```\n\n   启动一个停用的拓扑。也可以在Storm UI 界面上实现同样的功能 \n\n```shell\n Rebalance：storm rebalance topology_name [-w wait_time] [-n worker_count] [-e component_name=executer_count]... \n```\n\n rebalance使你重新分配集群任务。这是个很强大的命令。比如，你向一个运行中的集群增加了节点。rebalance命令将会停用拓扑，然后在相应超时时间之后重分配worker，并重启拓扑   \n\t\n\n```shell\nstorm rebalance wordcount-topology -w 15 -n 5 -e sentence-spout=4 -e split-bolt=8 \n```\n\n 还有其他管理命令，如：Remoteconfvalue、REPL、Classpath等 \n\n## Storm与Hadoop的对比\n\n![mark](https://img.jinguo.tech/blog/20200116/inthPTtTa26V.png?imageslim)\n\n## DRPC通过DRPC Server来实现，DRPC Server的整体工作过程如下：  \n\n引入DRPC主要是利用storm的实时计算能力来并行化CPU密集性的计算任务。  \n\n1. 接收到一个RPC调用请求；  \n2. 发送请求到Storm上的**拓扑**；  \n3. 从Storm上接收计算结果；  \n4. 将计算结果返回给客户端。  \n\n\n\n## 附录\n\n### maven更新镜像源\n\n```xml\n<mirrors>\n\t\t<!-- 阿里云仓库 -->\n\t          <mirror>\n\t              <id>alimaven</id>\n\t              <mirrorOf>central</mirrorOf>\n\t             <name>aliyun maven</name>\n\t             <url>https://maven.aliyun.com/repository/central</url>\n\t         </mirror>\n\t          <!-- 中央仓库1 -->\n         <mirror>\n             <id>repo1</id>\n             <mirrorOf>central</mirrorOf>\n             <name>Human Readable Name for this Mirror.</name>\n             <url>http://repo1.maven.org/maven2/</url>\n         </mirror>\n     \n         <!-- 中央仓库2 -->\n         <mirror>\n             <id>repo2</id>\n             <mirrorOf>central</mirrorOf>\n             <name>Human Readable Name for this Mirror.</name>\n             <url>http://repo2.maven.org/maven2/</url>\n         </mirror>\n     </mirrors> \n  </mirrors>\n\t         \n```\n\n## RPC和MQ对比及其适用/不适用场合\n\n### 系统结构  \n\n**RPC系统结构：**  \nCosume <=> Provider  \nConsumer调用的Provider提供的服务  \n\n**Message Queue系统结构：**  \nSender <=> Queue <=> Reciver  \nSender发送消息给Queue；Receiver从Queue拿到消息来处理。\n\n### 功能的特点\n\n在架构上，RPC和Message的差异点是，Message有一个中间结点Message Queue，可以把消息存储。  \n\n### 消息的特点\n\n- Message Queue把请求的压力保存一下，逐渐释放出来，让处理者按照自己的节奏来处理。\n- Message Queue引入一下新的结点，让系统的可靠性会受Message Queue结点的影响\n- Message Queue是异步单向的消息。发送消息设计成是不需要等待消息处理的完成。\n- 所以对于有同步返回需求，用Message Queue则变得麻烦了。\n\n### PRC的特点\n\n- 同步调用，对于要等待返回结果/处理结果的场景，RPC是可以非常自然直觉的使用方式。 \n- RPC也可以是异步调用。\n- 由于等待结果，Consumer（Client）会有线程消耗。\n- 如果以异步RPC的方式使用，Consumer（Client）线程消耗可以去掉。但不能做到像消息一样暂存消息/请求，压力会直接传导到服务Provider。   \n\n### 适用场合说明\n\n- 希望同步得到结果的场合，RPC合适。\n- 希望使用简单，则RPC；RPC操作基于接口，使用简单，使用方式模拟本地调用。异步的方式编程比较复杂。  \n- 不希望发送端（RPC Consumer、Message Sender）受限于处理端（RPC Provider、Message Receiver）的速度时，使用Message Queue。  \n- 随着业务增长，有的处理端处理量会成为瓶颈，会进行同步调用到异步消息的改造。\n- 这样的改造实际上有调整业务的使用方式。比如原来一个操作页面提交后就下一个页面会看到处理结果；改造后异步消息后，下一个页面就会变成“操作已提交，完成后会得到通知”。  \n\n### 不适用场合说明 \n\nRPC同步调用使用Message Queue来传输调用信息。  \n发送端是在等待，同时占用一个中间点的资源，没有对等的收益。RPC的方式可以保证调用返回即处理完成，使用消息方式后这一点不能保证了。\n\n"},{"title":"storm心得-上","url":"/2020/01/16/storm心得-上/","content":"\n# Storm入门\n\nStorm是一个**分布式的**，可靠的，容错的**数据流处理系统**。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。   \nStorm是Twitter开源的一个分布式的实时计算系统，用于数据的实时分析，持续计算，分布式RPC等等\nStorm是一个免费开源、分布式、高容错的实时计算系统。Storm令持续不断的流计算变得容易，弥补了Hadoop批处理所不能满足的实时要求。Storm经常用于在实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域。Storm的部署管理非常简单，而且，在同类的流式计算工具，Storm的性能也是非常出众的  \nStorm集群的输入流由一个被称作spout的组件管理，spout把数据传递给bolt， bolt要么把数据保存到某种存储器，要么把数据传递给其它的bolt。\n一个Storm集群就是在一连串的bolt之间转换spout传过来的数据。  \n注：Storm中的核心术语  \n**spout**龙卷，读取原始数据为bolt提供数据  \n**bolt** 雷电，从spout或其它bolt接收数据，并处理数据，处理结果可作为其它bolt的数据源或最终结果    \n**nimbus** 雨云，主节点的守护进程，负责为工作节点分发任务  \n**topology** 拓扑结构，Storm的一个任务单元  \n**define field(s)** 定义域，由spout或bolt提供，被bolt接收  \n\n## Storm应用案例\n\n- 数据处理流，Storm不需要中间队列\n- 连续计算。连续发送数据到客户端，使它们能够实时更新并显示结果。\n- **分布式远程过程调用**\n- 频繁的CPU密集型操作**并行化**。\n\n## Storm组件\n\n在Storm集群中，有两类节点：主节点master node和工作节点worker nodes。  \n主节点运行着一个叫做**Nimbus**的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。    \n**Supervisor**守护进程作为拓扑的一部分运行在工作节点上。  \n一个Storm**拓扑结构**在不同的机器上运行着众多的工作节点。\n因为Storm在**Zookeeper**或本地磁盘上**维持所有的集群状态**，守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康  \n在系统底层，Storm使用了**zeromq**，这是一种先进的，可嵌入的**网络通讯库**，它提供的绝妙功能使Storm成为可能。其中，Storm只用了push/pull sockets      \n\n### 注：zeromq的特性  \n\n- 一个并发架构的Socket库  \n- 对于集群产品和超级计算，比TCP要快    \n- 可通过inproc（进程内）, IPC（进程间）, TCP和multicast(多播协议)通信  \n- 异步I / O的可扩展的多核消息传递应用程序  \n- 利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现N-N连接  \n  注：最新的Storm已不再必须依赖**ZeroMQ**，各种依赖的库和软件也已经有更新的版本。\n  最近版本的Storm支持使用**netty**做消息队列。\n  Netty提供**异步的、事件驱动**的网络应用程序框架和工具，用以快速开发**高性能、高可靠性的**网络服务器和客户端程序。正好是 storm所需要的。\n\n## Storm的特性\n\n- 简化编程：使用Storm，实现实时处理的复杂性被大大降低了\n- 开发容易：使用一门基于JVM的语言开发会更容易，也可以借助一个小的中间件，在Storm上使用任何语言开发\n- 容错：Storm集群会关注工作节点状态，如果宕机了必要的时候会重新分配任务。\n- 可扩展：所有需要为扩展集群所做的工作就是增加机器。Storm会在新机器就绪时向它们分配任务。\n- 可靠的：所有消息都可保证至少处理一次。如果出错了，消息可能处理不只一次，永远不会丢失消息。\n- 快速：速度是驱动Storm设计的一个关键因素\n- 事务性：可以为几乎任何计算得到恰好一次消息语义\n\n## 安装Storm集群\n\n要手工安装Storm，需要先安装以下软件  \n\n1. Zookeeper集群\n2. Java\n3. Python\n4. Unzip命令\n\n### 注：\n\nNimbus和管理进程将要依赖Java、Python和unzip命令\n\n### 前期准备\n\n1. 准备搭建3节点集群,准备3个虚拟机node1,node2,node3  \n2. 配置好hosts映射文件和互相的ssh免密登录  \n3. 配置好JDK  \n   注：storm是依赖于zookeeper的,搭建storm集群前,必须先把zookeeper集群搭建好\n\n### 安装storm\n\n1. 准备好storm安装包\n2. 上传解压重命名为storm到/export/server路径下\n3. 修改配置文件 storm.yaml\n\n### 运行\n\n- 前台启动 (前台启动会占用窗口)  \n  （1）在node1上启动 nimbus进程(主节点) 和 web UI  \n  （2）在 node2 和 node3 上启动 supervisor(从节点)\n- 后台启动\n\n#### ssh脚本实现一键启动\n\n```shell\n.#!/bin/bash\nsource /etc/profile\nnohup /export/server/storm/bin/storm nimbus >/dev/null 2>&1 &\necho \"node1 nimbus is running\"\nnohup /export/server/storm/bin/storm ui >/dev/null 2>&1 &\necho \"node1 core is running\"\nfor host in node2 node3\ndo\n{\nssh $host \"source /etc/profile;nohup /export/server/storm/bin/storm supervisor >/dev/null 2>&1 &\"\necho \"$host Supervisor is running\"\n}\ndone\n```\n\n### 进入web页面查看集群\n\n## 使用入门\n\n### MAVEN依赖\n\n```xml\n<dependency>\n    <groupId>org.apache.storm</groupId>\n    <artifactId>storm-core</artifactId>\n    <version>1.1.1</version>\n    <!-- 目前<scope>可以使用5个值：\n    * compile，缺省值，适用于所有阶段，会随着项目一起发布。\n    * provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。\n    * runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。\n    * test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。\n    * system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。  -->\n    <!--<scope>provided</scope>-->\n</dependency>\n```\n\n### 编写Spout类读取日志文件中的内容, 并把数据发送给下游Bolt类进行处理\n\n```java\n/***\n * Version: \n * Description: 读取外部文件,把一行一行的数据发送给下游的bolt\n *              类似于hadoop mapreduce的inputformat\n ***/\n//BaseBasicSpout\npublic class ReadFileSpout extends BaseRichSpout {\n    private SpoutOutputCollector spoutOutputCollector;\n    private BufferedReader bufferedReader;\n    /**\n     * 初始化方法, 类似于这个类的构造器, 只被运行一次\n     * spout组件读取原始数据为bolt提供数据\n     * 一般用来打开数据链接, 打开网络连接\n     * @param map 传入的是storm集群的配置文件和用户自定义的配置文件, 一般不用\n     * @param topologyContext 上下文对象, 一般不用\n     * @param spoutOutputCollector 数据输出的收集器,spout把数据传给此参数,由此参数传给storm框架\n     */\n    public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector) {\n        try {\n        \t//本地模式\n            //this.bufferedReader = new BufferedReader(new FileReader(new File(\"D:\\\\wordcount.txt\")));\n            //集群模式\n            this.bufferedReader = new BufferedReader(new FileReader(new File(\"//root//stormdata//wordcount.txt\")));\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        }\n        this.spoutOutputCollector = spoutOutputCollector;\n    }\n\n    /**\n     * 下一个tuple, tuple是数据传送的基本单位\n     * 不断地往下一个组件发送tuple消息\n     * 这里面是该spout组件的核心逻辑\n     * 如从kafka消息队列中拿到数据\n     * 后台有个while方法一直调用该方法, 每调用一次就发送一个tuple出去\n     */\n    public void nextTuple() {\n        String line = null;\n        try {\n        \t//一行一行的读取文件内容,并且一行一行的发送\n            line = bufferedReader.readLine();\n            if (line != null){\n\t\t\t\t//将信息封装成tuple，发送消息给下一个组件\n\t\t        //this.collector.emit(new Value(this.words[index]));\n\n                spoutOutputCollector.emit(Arrays.asList(line));\n\n\t\t\t\t//每发送一个消息，休眠500ms\n       \t\t\t// Thread.sleep(500);\n\t\t\t\t// Utils.sleep(500);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 通过字段声明发出的数据是什么,tuple中的数据的字段名\n     * @param outputFieldsDeclarer\n     */\n    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n        outputFieldsDeclarer.declare(new Fields(\"line\"));\n    } \n}\n```\n\n### 编写Bolt类对出入的内容进行单词切分\n\n```java\n/***\n * Description: 输入一行一行的数据\n *              对一行数据进行切割\n *              输出单词及单词出现的次数\n ***\n//BaseBasicBolt\npublic class SplitBolt extends BaseRichBolt {\n    private OutputCollector outputCollector;\n    /**\n     * 初始化方法,只被运行一次\n     * @param map 配置文件\n     * @param topologyContext 上下文对象\n     * @param outputCollector 数据收集器\n     */\n    @Override\n    public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) {\n        this.outputCollector = outputCollector;\n    }\n\n    /**\n     * 执行业务逻辑的方法\n     * @param tuple 获取的上游数据\n     */\n    @Override\n    public void execute(Tuple tuple) {\n        //获取上游句子(字段:\"line\"),从tuple中读取数据\n\t\t//获取nextTuple()方法emit()过来的数据\t\n        String line = tuple.getStringByField(\"line\");\n        //对句子进行切割\n        String[] words = line.split(\" \");\n        //发送数据\n        for (String word : words) {\n            //需要发送单词和单词出现的次数,总共两个字段\n            outputCollector.emit(Arrays.asList(word, \"1\"));\n        }\n    }\n\n    /**\n     * 声明发送出去的数据\n     * @param outputFieldsDeclarer\n     */\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n        outputFieldsDeclarer.declare(new Fields(\"word\", \"num\"));\n    }\n}\n```\n\n### 编写Bolt类对单词进行计数\n\n```java\n/***\n* Description: 负责统计每个单词出现的次数, 类似于hadoop mapreduce的reduce\n*              输入单词及单词出现的次数\n*              输出打印在控制台\n***/\npublic class WordCountBolt extends BaseRichBolt {\n\t//定义一个map用于储存单词及其数量\n    private Map<String, Integer> wordCountMap = new HashMap<>();\n\n    /**\n     * 初始化方法\n     * @param map 配置文件\n     * @param topologyContext 上下文对象\n     * @param outputCollector 数据收集器\n     */\n    @Override\n    public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector) {\n        //由于WordCountBolt是最后一个bolt所以不需要提取出OutputCollector\n    }\n\n    @Override\n    public void execute(Tuple tuple) {\n        //获取信息(单词, 数量)\n        String word = tuple.getStringByField(\"word\");\n        String num = tuple.getStringByField(\"num\");\n        //使用map进行记录\n        //开始计数\n        if (wordCountMap.containsKey(word)){\n            //如果map里已经有这个单词,就把数量进行累加\n            Integer integer = wordCountMap.get(word);\n            wordCountMap.put(word, integer + Integer.parseInt(num));\n        }else {\n            //如果map里已经没有这个单词,就把单词和数量放入map\n            wordCountMap.put(word, Integer.parseInt(num));\n        }\n\n        //打印\n        System.out.println(wordCountMap);\n    }\n\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n        //由于不向外发送数据,所以不用写\n    }\n}\n```\n\n### 编写启动类对程序进行整合\n\n```\n/***\n * Description: wordcount驱动类,用来提交任务\n ***/\npublic class WordCountTopology {\n    public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {\n        //通过TopologyBuilder 封装任务信息\n        TopologyBuilder topologyBuilder = new TopologyBuilder();\n```\n\n​     \n\n```java\n        //设置spout获取数据\n        //SpoutDeclarer setSpout(String id, IRichSpout spout, Number parallelism_hint):参数:自定义id, spout对象, 并发数量 表示用多少个excutor来执行这个组件\n\t\t//setNumTasks(8)，设置该组件执行时并发的task数量，也就意味着1个excutor会执行8个task\n\n        topologyBuilder.setSpout(\"readfilesspout\", new ReadFileSpout(), 2);\n        //设置splitbolt 对句子进行切割\n        topologyBuilder.setBolt(\"splitbolt\", new SplitBolt(), 4).shuffleGrouping(\"readfilesspout\");\n        //设置wordcountbolt 对单词进行统计，将bolt设置到topology中，并且指定他接收的消息\n        topologyBuilder.setBolt(\"wordcountbolt\", new WordCountBolt(), 2).shuffleGrouping(\"splitbolt\");\n\n        //准备一个配置文件，配置一些topology在集群中运行的参数\n        Config config = new Config();\n\n        //启动2个worker!\n        config.setNumWorkers(2);\n\n        //任务提交有:本地模式 和 集群模式\n\n        //本地模式\n        //LocalCluster localCluster = new LocalCluster();\n        //localCluster.submitTopology(\"wordcount\", config, topologyBuilder.createTopology());\n\n        //集群模式,参数:Topology名字, 配置文件, Topology对象\n\t\t//用builder来创建topology\n        StormSubmitter.submitTopology(\"wordcount2\", config, topologyBuilder.createTopology());\n    }\n}\n```\n\n### 执行程序\n\n1. 选择本地模式运行  \n   直接运行驱动类的main方法即可, 统计后的结果会直接打印在控制台\n2. 选择上传到集群进行执行  \n   首先通过maven的package命名将程序打好jar包  \n\n#### 注：\n\n在storm-core的依赖中加入:<scope>provided</scope>  \n在上传到node2或node3上, 在指定路径下要确保存在日志文件\n\n# Storm Distributed RPC（DRPC）\n\n## 分布式远程过程调用\n\n- DRPC的主要作用就是利用Storm的**实时计算**能力来**并行化**CPU intensive的计算。  \n- 对于每一次函数调用，Storm topology将函数的参数当成是输入流，并且将函数运行的结果作为输出流。  \n- DRPC其实不能算是storm本身的一个特性，它是通过组合storm的**原语**spout，bolt，topology而成的一种模式(pattern)。  \n- DRPC通过一个\"DRPC server\"来进行**协调均衡**。（Storm整合了DRPC server的一个实现）。  \n- DRPC server接受一个RPC请求，发送该请求给Storm topology，接受该Storm topology产生的结果，并把结果返回给客户端。  \n- 对于客户端来说，一次DRPC调用就像是一次正常的RPC调用一样。\n\n### 客户端使用DRPC来获取以\"http://baidu.com\"为参数的\"reach\"函数的返回结果：\n\n```java\nDRPCClient client = new DRPCClient(\"drpc-host\", 3772);\nString result = client.execute(\"reach\", \"http://baidu.com\");\n```\n\n![mark](https://img.jinguo.tech/blog/20200116/rPnjrFMNdD6e.png?imageslim)  \n\n#### 1. 客户端将要执行的函数名以及相应的参数发送给DRPC server 。实现了这个函数的topology使用  \n\n#### 2. DRPCSpout来接收从DRPC server传来的函数的远程调用流，从而来执行该函数。\n\n#### 3. 每一次函数的远程调用都被DRPC server附上了一个唯一的id。\n\n#### 4. 接下来topology计算结果，在最后topology中的bolt调用ReturnResults来连接DRPC server并将结果及相应的函数远程调用id返回给DRPC server。\n\n#### 5. 接下来DRPC server通过id来匹配相应的客户端，此时客户端还处于等待状态，匹配上后，疏通等待状态的客户端，并开始将结果发送给客户端。\n\n## LinearDRPCTopologyBuilder（线性DRPCTopologyBuilder）\n\n### Storm中有个LinearDRPCTopologyBuilder，实现了几乎所以DRPC步骤的自动化,这些步骤如下:\n\n1. 建立 spout\n2. 将结果返回到DRPC server\n3. 向bolts提供了在tuples集合上进行有限聚集的功能\n\n#### 创建LinearDRPCTopologyBuilder\n\n```java\npublic static class ExclaimBolt extends BaseBasicBolt {\n    public void execute(Tuple tuple, BasicOutputCollector collector) {\n        String input = tuple.getString(1);\n\t\t//简单的在元组的第二个字段的值后加了一个\"!\"\n        collector.emit(new Values(tuple.getValue(0), input + \"!\"));\n    }\n```\n\n​\t\t\n\n```java\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"id\", \"result\"));\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n  //我们将DRPC函数名告诉给topology（本例函数名为exclamation）。\t\n  //单个DRPC server可以负责处理多个函数，函数之间通过函数名来进行区分。\n  //第一个bolt的输入是一个2元组，第一个字段为request id，第二个字段为request对应的参数。\n    LinearDRPCTopologyBuilder builder = new LinearDRPCTopologyBuilder(\"exclamation\");\n    builder.addBolt(new ExclaimBolt(), 3);\n}\n```\n\n#### 创建Local mode DRPC\n\n```java\n//首先创建一个LocalDRPC对象。该对象将会在进程中模拟一个DRPC server。\nLocalDRPC drpc = new LocalDRPC();\n//然后创建LocalCluster来以本地模式来运行该topology。\nLocalCluster cluster = new LocalCluster();\n//LinearDRPCTopologyBuilder有单独的方法来创建本地的topologies以及远程的topologies。\n//在本地模式中，LocalDRPC对象不会绑定到任何端口，所以，topology需要知道与其通信的对象\n//（即将drpc作为参数传入：builder. createLocalTopology(drpc)）;\ncluster.submitTopology(\"drpc-demo\", conf, builder.createLocalTopology(drpc));\n//在建立了topology后，我们可以使用LocalDRPC的execute进行DRPC远程调用。\nSystem.out.println(\"Results for 'hello':\" + drpc.execute(\"exclamation\", \"hello\"));\n\ncluster.shutdown();\ndrpc.shutdown();\n```\n\n#### Remote mode DRPC\n\n1. 建立DRPC servers\n2. 配置DRPC servers的位置\n3. 向Storm cluster提交DRPC topologies,可用storm脚本建立DRPC server：\n\n##### 1. 用storm脚本建立DRPC server：\n\n```java\nbin/storm drpc\n```\n\n##### 2. 配置DRPC servers位置，通过storm.yaml来进行配置或者在topology程序中进行配置\n\n```java\ndrpc.servers:\n  - \"drpc1.foo.com\"\n  - \"drpc2.foo.com\"\n```\n\n##### 3. 通过StormSubmitter建立DRPC topologies\n\n```java\nStormSubmitter.submitTopology(\"exclamation-drpc\", conf, builder.createRemoteTopology());\n```\n\n## Storm DRPC深入\n\n分布式dRPC（distributed RPC，DRPC）用于对Storm上大量的**函数调用**进行**并行计算**。对于每一次函数调用，Storm集群上运行的拓扑接收调用函数的参数信息作为输入流，并将计算结果作为输出流发射出去。  \n可概括为：Storm进行计算，根据客户端提交的请求参数，而返回Storm计算的结果。 \n\n### 注：\n\nStorm是一个流式计算框架，数据源源不断的产生，收集，计算。（数据实时产生、实时传输、实时计算、实时展示）  \nStorm只负责数据的计算，不负责数据的存储     \n2013年前后，阿里巴巴基于storm框架，使用java语言开发了类似的流式计算框架佳作，Jstorm。2016年年底阿里巴巴将源码贡献给了Apache storm，两个项目开始合并，新的项目名字叫做storm2.x \n\n![mark](https://img.jinguo.tech/blog/20200116/RcA2os1xUqfW.png?imageslim)\n**其中:**\nNimbus：负责资源分配和任务调度。  \nSupervisor：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。  \nWorker：运行具体处理组件逻辑的进程。  \nTask：worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，同一个spout/bolt的task可能会共享一个物理线程，该线程称为executor。  \n![mark](https://img.jinguo.tech/blog/20200116/nC49B0GwGz0o.png?imageslim)\n\n### 注：\n\n**DataSource**: 数据源  \n**Spout**：在一个topology中产生源数据流的组件。通常情况下spout会从外部数据源中读取数据，然后转换为topology内部的源数据。Spout是一个主动的角色，其接口中有个nextTuple()函数，storm框架会不停地调用此函数，用户只要在其中生成源数据即可。   \n**Bolt**：在一个topology中接受数据然后执行处理的组件。Bolt可以执行过滤、函数操作、合并、写数据库等任何操作。Bolt是一个被动的角色，其接口中有个execute(Tuple input)函数,在接受到消息后会调用此函数，用户可以在其中执行自己想要的操作。   \n**Tuple**：一次消息传递的基本单元。本来应该是一个key-value的map，但是由于各个组件间传递的tuple的字段名称已经事先定义好，所以tuple中只要按序填入各个value就行了，所以就是一个value list.  \n**Stream**：源源不断传递的tuple就组成了stream。  \n**Topology**：Storm中运行的一个实时应用程序，因为各个组件间的消息流动形成逻辑上的一个拓扑结构。\n\n### 分组策略\n\n1. 随机分组(Shuffle grouping)：随机分发tuple到Bolt的任务，保证每个任务获得相等数量的tuple。 跨服务器通信，浪费网络资源，尽量不适用\n2. 字段分组(Fields grouping)：根据指定字段分割数据流，并分组。例如，根据“user-id”字段，相同“user-id”的元组总是分发到同一个任务，不同“user-id”的元组可能分发到不同的任务。 跨服务器，除非有必要，才使用这种方式。\n3. LocalOrShuffle 分组。 优先将数据发送到本地的Task，节约网络通信的资源。\n\n\n\n## zookeeper安装和使用\n\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。  \nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。  \nZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper包含一个简单的原语集，提供Java和C的接口。    \n\n### zoo_sample.cfg文件配置\n\n```properties\n# The number of milliseconds of each tick\ntickTime=2000\n# The number of ticks that the initial \n# synchronization phase can take\ninitLimit=10\n# The number of ticks that can pass between \n# sending a request and getting an acknowledgement\nsyncLimit=5\n# the directory where the snapshot is stored.\n# do not use /tmp for storage, /tmp here is just \n# example sakes.\ndataDir=D:\\\\DevelopSoftware\\\\zookeeper\\\\zookeeper-3.4.14\\\\data\ndataLogDir=D:\\\\DevelopSoftware\\\\zookeeper\\\\zookeeper-3.4.14\\\\log\n# the port at which the clients will connect\nclientPort=2181\n# the maximum number of client connections.\n# increase this if you need to handle more clients\n#maxClientCnxns=60\n#\n# Be sure to read the maintenance section of the \n# administrator guide before turning on autopurge.\n#\n# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance\n#\n# The number of snapshots to retain in dataDir\n#autopurge.snapRetainCount=3\n# Purge task interval in hours\n# Set to \"0\" to disable auto purge feature\n#autopurge.purgeInterval=1\n```\n\n### 参数解释\n\n- tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。\n- initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 10 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 10*2000=20 秒\n- syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 5*2000=10 秒\n- dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。\n- clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。\n\n### 异常\n\nSocket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information  \n**解决办法：**将conf下的zoo_sample.cfg文件改成zoo.cfg文件。zkServer启动的时候要找到的zool.cfg而实际上在conf文件夹下面却是zoo_sample.cfg\n\nzookeeper启动成功\n![mark](https://img.jinguo.tech/blog/20200116/OVbwuEhqSMG5.png?imageslim)\n\n## Zookeeper伪分布式集群搭建\n\n1. 将Zookeeper解压后，复制三份，分别起名为8001,8002,8003，放到同一个目录中如zk-cluster。   \n2. 创建zk-data文件夹，在zk-data中新建8001,8002,8003文件夹。在每个文件夹下都创建data,log文件夹。\n3. 在上面创建的data目录下，创建myid文件，文件名就是myid，没有后缀，然后8001下的文件内容为1,8002下的myid内容为2，8003下的myid内容为3.  \n4. 修改zk-cluster中8001、8002、8003 下conf目录中的配置文件zoo.cfg ,下面是我8001下的zoo.cfg ,其中和8002，8003略作修改\n\n### zoo.cfg文件如下\n\n```properties\n# The number of milliseconds of each tick\n# 服务器与客户端之间交互的基本时间单元（ms）\ntickTime=2000\n# The number of ticks that the initial \n# synchronization phase can take\n# zookeeper所能接受的客户端数量\ninitLimit=10\n# The number of ticks that can pass between \n# sending a request and getting an acknowledgement\n# 服务器与客户端之间请求和应答的时间间隔\nsyncLimit=5\n# the directory where the snapshot is stored.\n# do not use /tmp for storage, /tmp here is just \n# example sakes.\n# 保存zookeeper数据，日志路径\ndataDir=D:/DevelopSoftware/zookeeper/zk-data/8001/data\ndataLogDir=D:/DevelopSoftware/zookeeper/zk-data/8001/log\n# the port at which the clients will connect\n# 这是客户端链接的端口号\nclientPort=2181\t\t\t\t\t\t\t\t\t\t\n# the maximum number of client connections.\n# increase this if you need to handle more clients\n#maxClientCnxns=60\n#\n# Be sure to read the maintenance section of the \n# administrator guide before turning on autopurge.\n#\n# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance\n#\n# The number of snapshots to retain in dataDir\n#autopurge.snapRetainCount=3\n# Purge task interval in hours\n# Set to \"0\" to disable auto purge feature\n#autopurge.purgeInterval=1\n\n# Cluster Zookeeper Server Address 下面配置不需要修改 要注意的就是，下面server.number (number是1、2、3)分别对应myid中的内容，zookeeper也是通过server后面的数字以及dataDir下的myid内容来判断zookeeper集群的关系的（哪个server对应哪个地址），然后后面两个端口号，一个是跟服务器发送链接的端口，另一个是接受服务器链接的端口\n# server.A=B:C:D  其中A是一个数字，代表这是第几号服务器；B是服务器的IP地址；C表示服务器与群集中的“领导者”交换信息的端口；当领导者失效后，D表示用来执行选举时服务器相互通信的端口。\n# 客户端与zookeeper相互交互的端口\nserver.1=127.0.0.1:8001:9001\nserver.2=127.0.0.1:8002:9002\nserver.3=127.0.0.1:8003:9003\n```\n\n### 报错\n\n```java\n [myid:1] - WARN  [WorkerSender[myid=1]:QuorumCnxManager@584] - Cannot open channel to 3 at election address /127.0.0.1:9003\njava.net.ConnectException: Connection refused: connect\n        at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)\n        at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85)\n        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\n        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n        at java.net.Socket.connect(Socket.java:589)\n        at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:558)\n        at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:534)\n        at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.process(FastLeaderElection.java:454)\n        at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.run(FastLeaderElection.java:435)\n        at java.lang.Thread.run(Thread.java:745)\n```\n\n### 报错解决办法\n\n产生上述Waring信息是因为zookeeper服务的每个实例都拥有全局的配置信息，他们在启动的时候需要随时随地的进行leader选举，此时server1就需要和其他两个zookeeper实例进行通信，但是，另外两个zookeeper实例还没有启动起来，因此将会产生上述所示的提示信息。当我们用同样的方式启动server2和server3后就不会再有这样的警告信息了。\n","tags":["Storm"],"categories":["大数据"]},{"title":"Netty教程","url":"/2020/01/16/Netty笔记/","content":"\n##  业界哪些流行的开源框架用Netty作为底层通信框架\n\n- Dubbo： 阿里开源的高性能RPC框架\n- RocketMQ： 阿里出品的高性能消息队列\n- Spark： 炙手可热的大数据处理引擎，底层使用Netty\n- Elasticsearch： 分布式多用户的全文搜索引擎\n- Apache Cassandra：开源分布式搜索数据库\n- Flink:分布式高性能高可用的流处理框架\n- Netty-SocketIO的java服务端实现\n- Spring5：使用Netty作为http协议框架\n- Play：简单易用的http服务器\n- Grpc:google开源的高性能rpc通信框架\n- Infinispan：针对缓存的高并发键值对数据存储\n- HornetQ：支持集群和多种协议，可嵌入、高性能的异步消息系统\n- Vert.x轻量级高性能能JVM应用平台\n  -<br>[完整的参考列表](https://netty.io/wiki/adopters.html)\n\n##  业界有哪些公司在使用Netty\n\n**在大型企业中**有：Apple、Twitter的Finagle、Facebook的Nifty、Google、Square、Instagram\n<br>**在初创企业中**有：做http长连接的**Firebase**、支持各种各样消息推送通知的**Urban Airship**\n<br><br> 当然，Netty也从这些项目中**受益**。通过实现 FTP、 SMTP、 HTTP 和 WebSocket 以及其他的基于二进制和基于文本的协议， Netty 扩展了它的应用范围及灵活性。\n\n##  Netty是什么\n\n1. **异步**和**事件驱动**的高性能网络通信框架。\n2. **特点:**它可以以任意的顺序响应在任意的时间点产生的事件，可以实现最高级别的可伸缩性。\n3. **目的:**用于快速开发高性能服务端和客户端\n4. **封装:**JDK底层BIO和NIO模型，提供高度可用的API,满足各类业务场景，其中ChannelHandler的热插拔机制解放了业务逻辑之外的细节问题，让业务逻辑的添加和删除非常容易\n5. 自带编解码器解决拆包粘包问题，用户只关心业务逻辑\n6. 精心设计的reactor线程模型支持高并发海量连接\n7. 自带各种协议栈如http、websocket，处理任何一种通信协议都几乎不用亲自动手\n8. **架构方法和设计原则：**每个小点都和它的技术性内容一样重要，穷其精妙。如关注点分离--业务和网络逻辑解耦，模块化和可复用性，可测试性。\n\n##  Netty的特性总结\n\n![mark](https://img.jinguo.tech/blog/20200116/556rRkzcJvAd.jpg?imageslim)\n\n##  Socket & Netty\n\n![Socket & Netty](https://img.jinguo.tech/blog/20200116/HPr4j4YYplQS.jpg?imageslim)\n\n##  Netty基本组件\n\n![mark](https://img.jinguo.tech/blog/20200116/YR8r6PSGf0P3.jpg?imageslim)\n\n- NioEventLoop ->Thread\n- Channel ->Socket  \t\n  NioSocketChannel implements Channel  \n  Chennel is a nexus to a network socket or a component which is capable operations such as read,write,connect,and bind\n- ByteBuf ->IO Bytes  \n  readBytes()、writeBytes() and so on\n- Pipline ->Logic Chain 逻辑链 \n- ChannelHandler ->Logic处理块\n\n##  Netty核心组件\n\n###  1. Channel-Socket\n\nChannel是通讯的载体，其基本构造是Socket  \n是对网络底层读写和连接原语言的抽象  \n\n###  2. EventLoop-控制流、多线程处理、并发\n\n定义了 Netty 的核心抽象， 用于处理连接的生命周期中所发生的事件\n\n###  注: Channel、 EventLoop、 Thread 以及EventLoopGroup 之间的关系\n\n![mark](https://img.jinguo.tech/blog/20200116/f3SuURuf0NE8.jpg?imageslim))\n\n##### A. 一个 EventLoopGroup 包含一个或者多个 EventLoop；  \n\n##### B. 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定\n\n##### C. 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理；\n\n##### D. 一个 Channel 在它的生命周期内只注册于一个 EventLoop；  \n\n##### E. 一个 EventLoop 可能会被分配给一个或多个 Channel\n\n##### F. 一个给定 Channel 的 I/O 操作都是由相同的 Thread 执行的， 实际上消除了对于同步的需要。\n\n###  3. ChannelFuture-异步通知\n\nNetty 中所有的 I/O 操作都是异步的,用于在之后的某个时间点确定其结果的方法\n\n###  4. ChannelHandler和ChannelPipeline\n\nChannelHandler负责Channel中的逻辑处理  \n其旨在简化应用程序处理逻辑的开发过程    \n充当了所有处理入站和出站数据的应用程序逻辑的容器  \nChannelHandler子接口：  \nChannelInboundHandler——处理入站数据以及各种状态变化  \nChannelOutboundHandler——处理出站数据并且允许拦截所有的操作  \nChannelInboundHandler的方法:  \n![mark](https://img.jinguo.tech/blog/20200116/BYvKbknKEu5E.png?imageslim)\nChannelOutboundHandler的方法:    \n![mark](https://img.jinguo.tech/blog/20200116/PJSBnLn25B3G.png?imageslim)\n\nChannelPipeline 提供了 ChannelHandler链的容器  \n定义了用于在该链上传播入站和出站事件流的API\n\n###  5. ByteBuf-Netty的数据容器\n\nJava NIO提供了ByteBuffer作为它的字节容器    \nNetty的ByteBuffer替代品是ByteBuf  \n\n##### A. 它可以被用户自定义的缓冲区类型扩展，通过内置的复合缓冲区类型实现了透明的零拷贝；  \n\n##### B.容量可以按需增长（类似于 JDK 的 StringBuilder）\n\n##### C.读和写使用了不同的索引\n\n##### D.支持方法的链式调用\n\n##### E.支持引用计数\n\n##### F.支持池化\n\n###  6. Bootstap-引导客户端和无连接协议\n\nBootstrap类负责为客户端和使用无连接协议的应用程序创建 Channel\n![](http://ww1.sinaimg.cn/large/005Vjva3gy1g2q8bxb9z6j30h109mgn0.jpg)\n\n##  单元测试\n\n使用EmbeddedChannel 测试 ChannelHandler  \n\n1. 测试入站消息  \n2. 测试出站消息  \n3. 测试异常处理  \n\n##  编解码器\n\n- 解码器   \n  将字节解码为消息  \n  将一种消息类型解码为另一种\n- 编码器  \n  将消息编码为字节  \n  将消息编码为消息\n\n##  Netty服务端启动\n\n1. 创建服务端Channel\n2. 初始化服务端Channel\n3. 注册Selector\n4. 端口绑定，实现对本地端口的接听\n\n##  预置的ChannelHandler和编解码器\n\n1. 通过 SSL/TLS 保护 Netty 应用程序\n2. ChannelHandler处理 HTTP 和 HTTPS协议\n3. 支持WebSocket\n4. ChannelHandler检测空闲连接以及超时\n5. FileRegion,通过支持零拷贝的文件传输的Channel来发送的文件区域\n6. 使用JDK、JBOSS Marshalling、Protocol Buffers序列化数据\n7. 使用UDP广播事件\n\n###  创建服务端Channel\n\n**bind()[用户代码入口] ->initAndRegister()[初始化并注册] ->newChannel()[创建服务端channel]**\n![mark](https://img.jinguo.tech/blog/20200116/IJvpJbzfX4Ik.jpg?imageslim)\n\n![mark](https://img.jinguo.tech/blog/20200116/T5pcP0vbkpy8.jpg?imageslim)\n\n![mark](https://img.jinguo.tech/blog/20200116/DaqDEJmk1sOn.jpg?imageslim)\n\n##  如何使用Netty进行RPC服务器的开发?\n\n1. 定义RPC请求消息、应答消息结构，里面要包括RPC的接口定义模块、包括远程调用的类名、方法名称、参数结构、参数值等信息。    \n2. 服务端初始化的时候通过容器加载RPC接口定义和RPC接口实现类对象的映射关系，然后等待客户端发起调用请求。\n3. 客户端发起的RPC消息里面包含，远程调用的类名、方法名称、参数结构、参数值等信息，通过网络，以字节流的方式送给RPC服务端，RPC服务端接收到字节流的请求之后，去对应的容器里面，查找客户端接口映射的具体实现对象。\n4. RPC服务端找到实现对象的参数信息，通过反射机制创建该对象的实例，并返回调用处理结果，最后封装成RPC应答消息通知到客户端。\n5. 客户端通过网络，收到字节流形式的RPC应答消息，进行拆包、解析之后，显示远程调用结果。\n   ![mark](https://img.jinguo.tech/blog/20200116/AVRTu5aellyr.png?imageslim) **客户端并发发起RPC调用请求，然后RPC服务端使用Netty连接器，分派出N个NIO连接线程，这个时候Netty连接器的任务结束。然后NIO连接线程是统一放到Netty NIO处理线程池进行管理，这个线程池里面会对具体的RPC请求连接进行消息编码、消息解码、消息处理等等一系列操作。最后进行消息处理（Handler）的时候，处于性能考虑，这里的设计是，直接把复杂的消息处理过程，丢给专门的RPC业务处理线程池集中处理，然后Handler对应的NIO线程就立即返回、不会阻塞。这个时候RPC调用结束，客户端会异步等待服务端消息的处理结果，通过消息回调机制实现。**\n   Netty对于RPC消息的解码、编码、处理对应的模块和流程，具体如下图所示：  \n6. ![mark](https://img.jinguo.tech/blog/20200116/hLvJCvXn7BzQ.png?imageslim)  \n   **客户端、服务端对RPC消息编码、解码、处理调用的模块以及调用顺序。    Netty把这样一个一个的处理器串在一起，形成一个责任链，统一进行调用。**\n\n\n\n##  附录\n\n###  Netty疑问\n\n1. Netty是什么？  \n   Netty是一个基于JAVA NIO类库的异步通信框架，它的架构特点是：异步非阻塞、基于事件驱动、高性能、高可靠性和高可定制性。\n2. 使用Netty能够做什么？  \n   ①开发异步、非阻塞的TCP网络应用程序；  \n   ②开发异步、非阻塞的UDP网络应用程序；  \n   ③开发异步文件传输应用程序；  \n   ④开发异步HTTP服务端和客户端应用程序；  \n   ⑤提供对多种编解码框架的集成；  \n   ⑥提供形式多样的编解码基础类库；  \n   ⑦基于职责链模式的Pipeline-Handler机制；\n   ⑧所有的IO操作都是异步的；\n   ⑨IP黑白名单控制，性能统计；\n   ⑩基于链路空闲事件检测的心跳检测；\n3. Netty在哪些行业得到了应用  \n   **①互联网行业：**随着网站规模的不断扩大，系统并发访问量也越来越高，传统基于Tomcat等Web容器的垂直架构已经无法满足需求，需要拆分应用进行服务化，以提高开发和维护效率。从组网情况看，垂直的架构拆分之后，系统采用分布式部署，各个节点之间需要远程服务调用，高性能的RPC框架必不可少，Netty作为异步高性能的通信框架，往往作为基础通信组件被这些RPC框架使用。  \n   典型的应用有：阿里分布式服务框架Dubbo的RPC框架使用Dubbo协议进行节点间通信，Dubbo协议默认使用Netty作为基础通信组件，用于实现各进程节点之间的内部通信。其中，服务提供者和服务消费者之间，服务提供者、服务消费者和性能统计节点之间使用Netty进行异步/同步通信。除了Dubbo之外，淘宝的消息中间件RocketMQ的消息生产者和消息消费者之间，也采用Netty进行高性能、异步通信。  \n   除了阿里系和淘宝系之外，很多其它的大型互联网公司或者电商内部也已经大量使用Netty构建高性能、分布式的网络服务器。  \n   **②大数据领域：**经典的Hadoop的高性能通信和序列化组件Avro的RPC框架，默认采用Netty进行跨节点通信，它的Netty Service基于Netty框架二次封装实现。大数据计算往往采用多个计算节点和一个/N个汇总节点进行分布式部署，各节点之间存在海量的数据交换。由于Netty的综合性能是目前各个成熟NIO框架中最高的，因此，往往会被选中用作大数据各节点间的通信。   \n   **③企业软件：**企业和IT集成需要ESB，Netty对多协议支持、私有协议定制的简洁性和高性能是ESB RPC框架的首选通信组件。事实上，很多企业总线厂商会选择Netty作为基础通信组件，用于企业的IT集成。  \n   **④通信行业：**Netty的异步高性能、高可靠性和高成熟度的优点，使它在通信行业得到了大量的应用。  \n   **⑤游戏行业：**无论是手游服务端、还是大型的网络游戏，Java语言得到了越来越广泛的应用。Netty作为高性能的基础通信组件，它本身提供了TCP/UDP和HTTP协议栈，非常方便定制和开发私有协议栈。账号登陆服务器、地图服务器之间可以方便的通过Netty进行高性能的通信。  \n4. 使用传统的Socket开发挺简单的，我为什么要切换到NIO进行编程呢？  \n   传统的同步阻塞IO通信存在如下几个问题：  \n   **①线程模型存在致命缺陷：**一连接一线程的模型导致服务端无法承受大量客户端的并发连接；  \n   **②性能差：**频繁的线程上下文切换导致CPU利用效率不高；  \n   **③可靠性差：**由于所有的IO操作都是同步的，所以业务线程只要进行IO操作，也会存在被同步阻塞的风险，这会导致系统的可靠性差，依赖外部组件的处理能力和网络的情况。  \n   **采用非阻塞IO（NIO）之后，同步阻塞IO的三个缺陷都将迎刃而解：**  \n   ①Nio采用Reactor模式*，一个Reactor线程聚合一个多路复用器Selector，它可以同时注册、监听和轮询成百上千个Channel，一个IO线程可以同时并发处理N个客户端连接，线程模型优化为1：N（N < 进程可用的最大句柄数）或者 M : N (M通常为CPU核数 + 1， N < 进程可用的最大句柄数)；   \n   ②由于IO线程总数有限，不会存在频繁的IO线程之间上下文切换和竞争，CPU利用率高；  \n   ③所有的IO操作都是异步的，即使业务线程直接进行IO操作，也不会被同步阻塞，系统不再依赖外部的网络环境和外部应用程序的处理性能。  \n   **由于切换到NIO编程之后可以为系统带来巨大的可靠性、性能提升，所以，目前采用NIO进行通信已经逐渐成为主流。**\n5. 为什么不直接基于JDK的NIO类库编程呢？  \n   即便抛开代码和NIO类库复杂性不谈，一个高性能、高可靠性的NIO服务端开发和维护成本都是非常高的，开发者需要具有丰富的NIO编程经验和网络维护经验，很多时候甚至需要通过抓包来定位问题。也许开发出一套NIO程序需要1个月，但是它的稳定很可能需要1年甚至更长的时间，这也就是为什么我不建议直接使用JDK NIO类库进行通信开发的一个重要原因。\n6. 为什么要选择Netty框架？  \n   Netty是业界最流行的NIO框架之一，它的健壮性、功能、性能、可定制性和可扩展性在同类框架中都是首屈一指的，它已经得到成百上千的商用项目验证，例如Hadoop的RPC框架Avro使用Netty作为通信框架。很多其它业界主流的RPC和分布式服务框架，也使用Netty来构建高性能的异步通信能力。\n   Netty的优点总结如下：  \n   ①API使用简单，开发门槛低；  \n   ②功能强大，预置了多种编解码功能，支持多种主流协议；  \n   ③定制能力强，可以通过ChannelHandler对通信框架进行灵活的扩展；  \n   ④性能高，通过与其它业界主流的NIO框架对比，Netty的综合性能最优；  \n   ⑤成熟、稳定，Netty修复了已经发现的所有JDK NIO BUG，业务开发人员不需要再为NIO的BUG而烦恼；  \n   ⑥社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会被加入；  \n   ⑦经历了大规模的商业应用考验，质量得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它完全满足不同行业的商用标准。\n\n##  代码\n\n###  1. 基于Netty的客户端和服务端的简单通信\n\n##### 要点：\n\n①为初始化客户端， 创建了一个 Bootstrap 实例  \n②为进行事件处理分配了一个 NioEventLoopGroup 实例， 其中事件处理包括创建新的连接以及处理入站和出站数据；  \n③为服务器连接创建了一个 InetSocketAddress 实例；    \n④当连接被建立时，一个 EchoClientHandler 实例会被安装到（该 Channel 的）ChannelPipeline 中；  \n⑤在一切都设置完成后，调用 Bootstrap.connect()方法连接到远程节点；  \n![mark](https://img.jinguo.tech/blog/20200116/cIhXBNgNE4y8.png?imageslim)\n\n`<!--more-->` \n\n### EchoServer\n\n### EchoServerHandler\n\n##### channelRead()—对于每个传入的消息都要调用；\n\n##### channelReadComplete()—通知ChannelInboundHandler最后一次对channelRead()的调用是当前批量读取中的最后一条消息；\n\n##### exceptionCaught()—在读取操作期间，有异常抛出时会调用。\n\n```Java\n\t//标示一个ChannelHandler可以被多个 Channel 安全地共享\n\t\t@Sharable\n\t\tpublic class EchoServerHandler extends ChannelInboundHandlerAdapter {\n\t\t    @Override\n\t\t    public void channelRead(ChannelHandlerContext ctx, Object msg) {\n\t\t        ByteBuf in = (ByteBuf) msg;\n\t\t        //将消息记录到控制台\n\t\t        System.out.println(\"Server received: \" + in.toString(CharsetUtil.UTF_8));\n\t\t        //将接收到的消息写给发送者，而不冲刷出站消息\n\t\t        ctx.write(in);\n\t\t    }\n             @Override\n\t    \tpublic void channelReadComplete(ChannelHandlerContext ctx)throws Exception {\n\t        \t//将未决消息冲刷到远程节点，并且关闭该 Channel\n\t        \tctx.writeAndFlush(Unpooled.EMPTY_BUFFER).addListener(ChannelFutureListener.CLOSE);\n\t    \t}\n\t\n\t    @Override\n\t    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) {\n\t        //打印异常栈跟踪\n\t        cause.printStackTrace();\n\t        //关闭该Channel\n\t        ctx.close();\n\t    }\n\t}\n```\n\n###  EchoServer\n\n##### 绑定到服务器将在其上监听并接受传入连接请求的端口；\n\n##### 配置 Channel，以将有关的入站消息通知给 EchoServerHandler 实例。\n\n```java\npublic class EchoServer {\n    private final int port;\n\n    public EchoServer(int port) {\n        this.port = port;\n    }\n\n    public static void main(String[] args)\n            throws Exception {\n        if (args.length != 1) {\n            System.err.println(\"Usage: \" + EchoServer.class.getSimpleName() +\" <port>\"\n            );\n            return;\n        }\n        //设置端口值（如果端口参数的格式不正确，则抛出一个NumberFormatException）\n        int port = Integer.parseInt(args[0]);\n        //调用服务器的 start()方法\n        new EchoServer(port).start();\n    }\n\n    public void start() throws Exception {\n        final EchoServerHandler serverHandler = new EchoServerHandler();\n        //(1) 创建EventLoopGroup\n        EventLoopGroup group = new NioEventLoopGroup();\n        try {\n            //(2) 创建ServerBootstrap\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(group)\n                    //(3) 指定所使用的 NIO 传输 Channel\n                    .channel(NioServerSocketChannel.class)\n                    //(4) 使用指定的端口设置套接字地址\n                    .localAddress(new InetSocketAddress(port))\n                    //(5) 添加一个EchoServerHandler到于Channel的 ChannelPipeline\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch) throws Exception {\n                            //EchoServerHandler 被标注为@Shareable，所以我们可以总是使用同样的实例\n                            //这里对于所有的客户端来说，都会使用同一个 EchoServerHandler，因为其被标注@Sharable，\n                            ch.pipeline().addLast(serverHandler);\n                        }\n                    });\n            //(6) 异步地绑定服务器；调用 sync()方法阻塞等待直到绑定完成\n            ChannelFuture f = b.bind().sync();\n            System.out.println(EchoServer.class.getName() +\n                    \" started and listening for connections on \" + f.channel().localAddress());\n            //(7) 获取 Channel 的CloseFuture，并且阻塞当前线程直到它完成\n            f.channel().closeFuture().sync();\n        } finally {\n            //(8) 关闭 EventLoopGroup，释放所有的资源\n            grop.shutdownGracefully().sync();\n        }\n    }\n}\n```\n\n###  通过 ChannelHandler 实现客户端逻辑\n\n##### channelActive()——在到服务器的连接已经建立之后将被调用；\n\n##### channelRead0()——当服务器接收到一条消息时被调用\n\n##### exceptionCaught()——在处理过程中引发异常时被调用。\n\n```java\n@Sharable\n//标记该类的实例可以被多个 Channel 共享\npublic class EchoClientHandler extends SimpleChannelInboundHandler<ByteBuf> {\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) {\n        //当被通知 Channel是活跃的时候，发送一条消息\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"Netty rocks!\",CharsetUtil.UTF_8));\n    }\n\n    @Override\n    public void channelRead0(ChannelHandlerContext ctx, ByteBuf in) {\n        //记录已接收消息的转储\n        System.out.println(\"Client received: \" + in.toString(CharsetUtil.UTF_8));\n    }\n\n    @Override\n    //在发生异常时，记录错误并关闭Channel\n    public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause) {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n\t\t\n```\n\n###  引导客户端\n\n##### 客户端是使用主机和端口参数来连接远程地址，也就是Echo 服务器的地址，而不是绑定到一个一直被监听的端口\n\n```java\npublic class EchoClient {\n    private final String host;\n    private final int port;\n\n    public EchoClient(String host, int port) {\n        this.host = host;\n        this.port = port;\n    }\n\n    public void start()\n            throws Exception {\n        EventLoopGroup group = new NioEventLoopGroup();\n        try {\n            //创建 Bootstrap\n            Bootstrap b = new Bootstrap();\n            //指定 EventLoopGroup 以处理客户端事件；需要适用于 NIO 的实现\n            b.group(group)\n                    //适用于 NIO 传输的Channel 类型\n                    .channel(NioSocketChannel.class)\n                    //设置服务器的InetSocketAddress\n                    .remoteAddress(new InetSocketAddress(host, port))\n                    //在创建Channel时，向 ChannelPipeline中添加一个 EchoClientHandler实例\n                    .handler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        public void initChannel(SocketChannel ch)\n                                throws Exception {\n                            ch.pipeline().addLast(\n                                    new EchoClientHandler());\n                        }\n                    });\n            //连接到远程节点，阻塞等待直到连接完成\n            ChannelFuture f = b.connect().sync();\n            //阻塞，直到Channel 关闭\n            f.channel().closeFuture().sync();\n        } finally {\n            //关闭线程池并且释放所有的资源\n            group.shutdownGracefully().sync();\n        }\n    }\n\n    public static void main(String[] args)\n            throws Exception {\n        if (args.length != 2) {\n            System.err.println(\"Usage: \" + EchoClient.class.getSimpleName() +\n                    \" <host> <port>\"\n            );\n            return;\n        }\n\n        final String host = args[0];\n        final int port = Integer.parseInt(args[1]);\n        new EchoClient(host, port).start();\n    }\n}\n```\n\n###  2. 基于Zookeeper、Netty和Spring的轻量级的分布式RPC框架\n\n##### 简易RPC有如下特性：\n\n- 服务异步调用的支持，回调函数callback的支持\n- 客户端使用长连接（在多次调用共享连接）\n- 服务端异步多线程处理RPC请求\n- 服务发布与订阅：服务端使用Zookeeper注册服务地址，客户端从Zookeeper获取可用的服务地址。\n- 通信：使用Netty作为通信框架\n- Spring：使用Spring配置服务，加载Bean，扫描注解\n- 动态代理：客户端使用代理模式透明化服务调用\n- 消息编解码：使用Protostuff序列化和反序列化消息\n\n##### RPC介绍\n\nRPC，即 Remote Procedure Call（远程过程调用），调用远程计算机上的服务，就像调用本地服务一样。RPC可以很好的解耦系统，如WebService就是一种基于Http协议的RPC。\n\n![mark](https://img.jinguo.tech/blog/20200116/b2FvBccopV9G.png?imageslim)\n\n- 服务端发布服务\n\n#####  服务注解：\n\n```java\n\t@Target({ElementType.TYPE})\n\t@Retention(RetentionPolicy.RUNTIME)\n\t@Component\n\tpublic @interface RpcService {\n\t    Class<?> value();\n\t}\n```\n\n#####  一个服务接口：\n\n```java\npublic interface HelloService {\nString hello(String name);\n\t   String hello(Person person);\n}\n```\n\n#####  一个服务实现：使用注解标注：\n\n```java\n@RpcService(HelloService.class)\npublic class HelloServiceImpl implements HelloService {\n    @Override\n    public String hello(String name) {\n        return \"Hello! \" + name;\n    }\n\n    @Override\n    public String hello(Person person) {\n        return \"Hello! \" + person.getFirstName() + \" \" + person.getLastName()\n    }\n}\n\n```\n\n#####  服务在启动的时候扫描得到所有的服务接口及其实现：\n\n```java\n\t@Override\n\tpublic void setApplicationContext(ApplicationContext ctx) throws BeansException {\n\t      Map<String, Object> serviceBeanMap = ctx.getBeansWithAnnotation(RpcService.class);\n\t      if (MapUtils.isNotEmpty(serviceBeanMap)) {\n\t        for (Object serviceBean : serviceBeanMap.values()) {\n\t            String interfaceName =              serviceBean.getClass().getAnnotation(RpcService.class).value().getName();\n\t            handlerMap.put(interfaceName, serviceBean);\n\t         }\n\t      }\n\t  }\n```\n\n#####  在Zookeeper集群上注册服务地址：\n\n```java\npublic class ServiceRegistry {\n    private static final Logger LOGGER = LoggerFactory.getLogger(ServiceRegistry.class);\n\n    private CountDownLatch latch = new CountDownLatch(1);\n\n    private String registryAddress;\n\n    public ServiceRegistry(String registryAddress) {\n        this.registryAddress = registryAddress;\n    }\n\n    public void register(String data) {\n        if (data != null) {\n            ZooKeeper zk = connectServer();\n            if (zk != null) {\n                AddRootNode(zk); // Add root node if not exist\n                createNode(zk, data);\n            }\n        }\n    }\n\n    private ZooKeeper connectServer() {\n        ZooKeeper zk = null;\n        try {\n            zk = new ZooKeeper(registryAddress, Constant.ZK_SESSION_TIMEOUT, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        latch.countDown();\n                    }\n                }\n            });\n            latch.await();\n        } catch (IOException e) {\n            LOGGER.error(\"\", e);\n        } catch (InterruptedException ex) {\n            LOGGER.error(\"\", ex);\n        }\n        return zk;\n    }\n\n    private void AddRootNode(ZooKeeper zk) {\n        try {\n            Stat s = zk.exists(Constant.ZK_REGISTRY_PATH, false);\n            if (s == null) {\n                zk.create(Constant.ZK_REGISTRY_PATH, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        } catch (KeeperException e) {\n            LOGGER.error(e.toString());\n        } catch (InterruptedException e) {\n            LOGGER.error(e.toString());\n        }\n    }\n\n    private void createNode(ZooKeeper zk, String data) {\n        try {\n            byte[] bytes = data.getBytes();\n            String path = zk.create(Constant.ZK_DATA_PATH, bytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);\n            LOGGER.debug(\"create zookeeper node ({} => {})\", path, data);\n        } catch (KeeperException e) {\n            LOGGER.error(\"\", e);\n        } catch (InterruptedExceptin ex) {\n            LOGGER.error(\"\", ex);\n        }\n    }\n}\n\t    \n```\n\n#####  客户端使用代理模式调用服务：\n\n```java\npublic class ServiceRegistry {\n    private static final Logger LOGGER = LoggerFactory.getLogger(ServiceRegistry.class);\n\n    private CountDownLatch latch = new CountDownLatch(1);\n\n    private String registryAddress;\n\n    public ServiceRegistry(String registryAddress) {\n        this.registryAddress = registryAddress;\n    }\n\n    public void register(String data) {\n        if (data != null) {\n            ZooKeeper zk = connectServer();\n            if (zk != null) {\n                AddRootNode(zk); // Add root node if not exist\n                createNode(zk, data);\n            }\n        }\n    }\n\n    private ZooKeeper connectServer() {\n        ZooKeeper zk = null;\n        try {\n            zk = new ZooKeeper(registryAddress, Constant.ZK_SESSION_TIMEOUT, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        latch.countDown();\n                    }\n                }\n            });\n            latch.await();\n        } catch (IOException e) {\n            LOGGER.error(\"\", e);\n        } catch (InterruptedException ex) {\n            LOGGER.error(\"\", ex);\n        }\n        return zk;\n    }\n\n    private void AddRootNode(ZooKeeper zk) {\n        try {\n            Stat s = zk.exists(Constant.ZK_REGISTRY_PATH, false);\n            if (s == null) {\n                zk.create(Constant.ZK_REGISTRY_PATH, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        } catch (KeeperException e) {\n            LOGGER.error(e.toString());\n        } catch (InterruptedException e) {\n            LOGGER.error(e.toString());\n        }\n    }\n\n    private void createNode(ZooKeeper zk, String data) {\n        try {\n            byte[] bytes = data.getBytes();\n            String path = zk.create(Constant.ZK_DATA_PATH, bytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);\n            LOGGER.debug(\"create zookeeper node ({} => {})\", path, data);\n        } catch (KeeperException e) {\n            LOGGER.error(\"\", e);\n        } catch (InterruptedException ex) {\n            LOGGER.error(\"\", ex);\n        }\n    }\n}\n\n```\n\n#####  从Zookeeper上获取服务地址：\n\n```java\npublic class ServiceDiscovery {\n    private static final Logger LOGGER = LoggerFactory.getLogger(ServiceDiscovery.class);\n\n    private CountDownLatch latch = new CountDownLatch(1);\n\n    private volatile List<String> dataList = new ArrayList<>();\n\n    private String registryAddress;\n\n    public ServiceDiscovery(String registryAddress) {\n        this.registryAddress = registryAddress;\n        ZooKeeper zk = connectServer();\n        if (zk != null) {\n            watchNode(zk);\n        }\n    }\n\n    public String discover() {\n        String data = null;\n        int size = dataList.size();\n        if (size > 0) {\n            if (size == 1) {\n                data = dataList.get(0);\n                LOGGER.debug(\"using only data: {}\", data);\n            } else {\n                data = dataList.get(ThreadLocalRandom.current().nextInt(size));\n                LOGGER.debug(\"using random data: {}\", data);\n            }\n        }\n        return data;\n    }\n\n    private ZooKeeper connectServer() {\n        ZooKeeper zk = null;\n        try {\n            zk = new ZooKeeper(registryAddress, Constant.ZK_SESSION_TIMEOUT, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        latch.countDown();\n                    }\n                }\n            });\n            latch.await();\n        } catch (IOException | InterruptedException e) {\n            LOGGER.error(\"\", e);\n        }\n        return zk;\n    }\n\n    private void watchNode(final ZooKeeper zk) {\n        try {\n            List<String> nodeList = zk.getChildren(Constant.ZK_REGISTRY_PATH, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getType() == Event.EventType.NodeChildrenChanged) {\n                        watchNode(zk);\n                    }\n                }\n            });\n            List<String> dataList = new ArrayList<>();\n            for (String node : nodeList) {\n                byte[] bytes = zk.getData(Constant.ZK_REGISTRY_PATH + \"/\" + node, false, null);\n                dataList.add(new String(bytes));\n            }\n            LOGGER.debug(\"node data: {}\", dataList);\n            this.dataList = dataList;\n        } catch (KeeperException | InterrupteException e) {\n            LOGGER.error(\"\", e);\n        }\n    }\n}\n\n```\n\n#####  消息编码 请求消息：\n\n```java\npublic class RpcRequest {\n    private String requestId;\n    private String className;\n    private String methodName;\n    private Class<?>[] parameterTypes;\n    private Object[] parameters;\n\n    public String getRequestId() {\n        return requestId;\n    }\n\n    public void setRequestId(String requestId) {\n        this.requestId = requestId;\n    }\n\n    public String getClassName() {\n        return className;\n    }\n\n    public void setClassName(String className) {\n        this.className = className;\n    }\n\n    public String getMethodName() {\n        return methodName;\n    }\n\n    public void setMethodName(String methodName) {\n        this.methodName = methodName;\n    }\n\n    public Class<?>[] getParameterTypes() {\n        return parameterTypes;\n    }\n\n    public void setParameterTypes(Class<?>[] parameterTypes) {\n        this.parameterTypes = parameterTypes;\n    }\n\n    public Object[] getParameters() {\n        return parameters;\n    }\n\n    public void setParameters(Object[] parameters) {\n        this.parameters = parameters;\n    }\n}\n\t  \n```\n\n#####  响应消息：\n\n```java\npublic class RpcResponse {\n    private String requestId;\n    private String error;\n    private Object result;\n\n    public boolean isError() {\n        return error != null;\n    }\n\n    public String getRequestId() {\n        return requestId;\n    }\n\n    public void setRequestId(String requestId) {\n        this.requestId = requestId;\n    }\n\n    public String getError() {\n        return error;\n    }\n\n    public void setError(String error) {\n        this.error = error;\n    }\n\n    public Object getResult() {\n        return result;\n    }\n\n    public void setResult(Object result) {\n        this.result = result;\n    }\n}\n\t\n```\n\n#####  消息序列化和反序列化工具：（基于 Protostuff 实现）\n\n```java\npublic class SerializationUtil {\n    private static Map<Class<?>, Schema<?>> cachedSchema = new ConcurrentHashMap<>();\n\n    private static Objenesis objenesis = new ObjenesisStd(true);\n\n    private SerializationUtil() {\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private static <T> Schema<T> getSchema(Class<T> cls) {\n        Schema<T> schema = (Schema<T>) cachedSchema.get(cls);\n        if (schema == null) {\n            schema = RuntimeSchema.createFrom(cls);\n            if (schema != null) {\n                cachedSchema.put(cls, schema);\n            }\n        }\n        return schema;\n    }\n\n    /**\n     * 序列化（对象 -> 字节数组）\n     */\n    @SuppressWarnings(\"unchecked\")\n    public static <T> byte[] serialize(T obj) {\n        Class<T> cls = (Class<T>) obj.getClass();\n        LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE);\n        try {\n            Schema<T> schema = getSchema(cls);\n            return ProtostuffIOUtil.toByteArray(obj, schema, buffer);\n        } catch (Exception e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        } finally {\n            buffer.clear();\n        }\n    }\n\n    /**\n     * 反序列化（字节数组 -> 对象）\n     */\n    public static <T> T deserialize(byte[] data, Class<T> cls) {\n        try {\n            T message = (T) objenesis.newInstance(cls);\n            Schema<T> schema = getSchema(cls);\n            ProtostuffIOUtil.mergeFrom(data, message, schema);\n            return message;\n        } catch (Exception e) {\n            throw new IllegalStatexception(e.getMessage(), e);\n        }\n    }\n}\n```\n\n#####  性能改进 服务端请求异步处理\n\n```java\npublic void channelRead0(final ChannelHandlerContext ctx,final RpcRequest request) throws Exception {\n        RpcServer.submit(new Runnable() {\n            @Override\n            public void run() {\n                LOGGER.debug(\"Receive request \" + request.getRequestId());\n                RpcResponse response = new RpcResponse();\n                response.setRequestId(request.getRequestId());\n                try {\n                    Object result = handle(request);\n                    response.setResult(result);\n                } catch (Throwable t) {\n                    response.setError(t.toString());\n                    LOGGER.error(\"RPC Server handle request error\",t);\n                }\n                ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE).addListener(new ChannelFutureListener() {\n                    @Override\n                    public void operationComplete(ChannelFuture channelFuture) throws Exception {\n                        LOGGER.debug(\"Send response for request \" + request.getRequestId());\n                    }\n                });\n            }\n        });\n    }\n```\n\n#####  服务端长连接的管理\n\n客户端保持和服务进行**长连接**，不需要每次调用服务的时候进行连接，长连接的管理（通过Zookeeper获取有效的地址）。  \n通过监听Zookeeper服务节点值的变化，动态更新客户端和服务端保持的长连接。这个事情现在放在客户端在做，客户端保持了和所有可用服务的长连接，给客户端和服务端都造成了压力，需要解耦这个实现。\n\n#####  客户端请求异步处理\n\n**客户端请求异步处理的支持，不需要同步等待：发送一个异步请求，返回Future，通过Future的callback机制获取结果。**\n\n```java\n\tIAsyncObjectProxy client = rpcClient.createAsync(HelloService.class);\n\tRPCFuture helloFuture = client.call(\"hello\", Integer.toString(i));\n\tString result = (String) helloFuture.get(3000, TimeUnit.MILLISECONDS);\n```\n\n","tags":["Netty"],"categories":["Java"]},{"title":"RocketMQ知识点","url":"/2020/01/16/RocketMQ知识点/","content":"\n## 1. RocketMQ 是什么\n\n#### RocketMQ是一款[^低延迟的]、[^高可靠的]、[^可伸缩的]、易于使用的消息中间件\n\n[^低延迟的]: 响应时间低，比如一个网页在几秒内打开，越短表示延迟越低\n[^高可靠的]: 指的是运行时间能够满足预计时间的一个系统或组件\n[^可伸缩的]: 可伸缩性是高性能、低成本和可维护性等多因素的综合考量和平衡\n\n\n\n#### RocketMQ具有以下特性\n\n- 支持发布/订阅（Pub/Sub）和点对点（P2P）消息模型\n- 在一个队列中可靠的先进先出（FIFO）和严格的顺序传递\n- 支持拉（pull）和推（push）两种消息模式\n- 单一队列百万消息的堆积能力\n- 支持多种消息协议，如 JMS、MQTT 等\n- 分布式高可用的部署架构,满足至少一次消息传递语义\n- 提供 docker 镜像用于隔离测试和云集群部署\n- 提供配置、指标和监控等功能丰富的 Dashboard\n\n\n\n> ### Producer\n>\n> **消息生产者**，生产者的作用就是将消息发送到 MQ。生产者本身既可以产生消息，如读取文本信息等，也可以对外提供接口，由外部应用调用接口传递消息，再由生产者将收到的消息发送到 MQ。\n>\n> ### Producer Group\n>\n> **生产者组**，就是多个发送同一类消息的生产者称之为一个生产者组。\n\n\n\n> ### Consumer\n>\n> **消息消费者**，消费 MQ 上的消息的应用程序就是消费者，至于消息是否进行逻辑处理，还是直接存储到数据库等取决于业务需要。\n>\n> ### Consumer Group\n>\n> **消费者组**，消费同一类消息的多个 consumer 实例组成一个消费者组。\n\n\n\n> ### Topic\n>\n> *Topic* 是一种消息的逻辑分类。比如说有订单类的消息，也有库存类的消息，那么就需要进行分类，一个是订单 Topic 存放订单相关的消息，一个是库存 Topic 存储库存相关的消息。以此类推\n>\n> ### Message\n>\n> *Message*是消息的载体。一个 Message 必须指定 topic，相当于寄信的地址。Message 还有一个可选的 tag 设置，以便消费端可以基于 tag 进行过滤消息。也可以添加额外的键值对，例如需要一个业务 key 来查找 broker 上的消息，方便在开发过程中诊断问题。\n>\n> \n\n\n\n> ### Tag\n>\n> *Tag***标签**可以被认为是对Topic进一步细化。一般在相同业务模块中通过标签来标记不同用途的消息\n>\n> ### Broker\n>\n> *Broker*是RocketMQ系统的主要角色，即MQ。Broker接收来自生产者的消息，储存，以及为消费者拉取消息的请求做好准备\n>\n> ### Name Server\n>\n> *Name Server* 为 producer 和 consumer 提供路由信息。\n\n\n\n","tags":["消息队列"],"categories":["Java"]}]